{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62c2305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da38a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /Library/Frameworks/Python.framework/Versions/3.8/include/python3.8/UNKNOWN\n",
      "sysconfig: /Library/Frameworks/Python.framework/Versions/3.8/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.13.1-cp38-cp38-macosx_10_15_x86_64.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from statsmodels) (1.2.4)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from statsmodels) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from statsmodels) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas>=0.25->statsmodels) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas>=0.25->statsmodels) (2.8.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels) (1.15.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /Library/Frameworks/Python.framework/Versions/3.8/include/python3.8/UNKNOWN\n",
      "sysconfig: /Library/Frameworks/Python.framework/Versions/3.8/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed patsy-0.5.2 statsmodels-0.13.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# to install package\n",
    "import sys\n",
    "!{sys.executable} -m pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d974d071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Company</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Rating</th>\n",
       "      <th>Company Rating Numbers</th>\n",
       "      <th>Company Size</th>\n",
       "      <th>Company Founded</th>\n",
       "      <th>Company Type</th>\n",
       "      <th>Company Industry</th>\n",
       "      <th>Company Sector</th>\n",
       "      <th>Company Revenue</th>\n",
       "      <th>Level</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Senior Data Scientist - Ads Optimization</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>4.3</td>\n",
       "      <td>703</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>2004</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$2 to $5 billion (USD)</td>\n",
       "      <td>Senior</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>223000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technical Sourcer - Data Science &amp; Analytics</td>\n",
       "      <td>Uber</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3142</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>2009</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>Normal</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>167000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Senior Data Science Analyst</td>\n",
       "      <td>JM Talent Inc.</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Senior</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Science Lecturer</td>\n",
       "      <td>Excelon Associates</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>2007</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Staffing &amp; Outsourcing</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>Less than $1 million (USD)</td>\n",
       "      <td>Normal</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Warman O'Brien</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>2017</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Staffing &amp; Outsourcing</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$5 to $10 million (USD)</td>\n",
       "      <td>Normal</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5656</th>\n",
       "      <td>5656</td>\n",
       "      <td>Software Engineer - C#/.Net</td>\n",
       "      <td>Canalyst</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Normal</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>5657</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Prenuvo</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>0</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Health Care Services &amp; Hospitals</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Normal</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infra/System SWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>5658</td>\n",
       "      <td>Software Engineer 1</td>\n",
       "      <td>WELL Health Technologies Corp</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Normal</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>5659</td>\n",
       "      <td>Software Engineer / Full Stack Developer</td>\n",
       "      <td>MPM Engineering</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Normal</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Stack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>5660</td>\n",
       "      <td>software engineer</td>\n",
       "      <td>postalong technology inc.</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Normal</td>\n",
       "      <td>99840.0</td>\n",
       "      <td>99840.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5661 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                     Job Title  \\\n",
       "0              0      Senior Data Scientist - Ads Optimization   \n",
       "1              1  Technical Sourcer - Data Science & Analytics   \n",
       "2              2                   Senior Data Science Analyst   \n",
       "3              3                         Data Science Lecturer   \n",
       "4              4                                Data Scientist   \n",
       "...          ...                                           ...   \n",
       "5656        5656                   Software Engineer - C#/.Net   \n",
       "5657        5657                               DevOps Engineer   \n",
       "5658        5658                           Software Engineer 1   \n",
       "5659        5659      Software Engineer / Full Stack Developer   \n",
       "5660        5660                             software engineer   \n",
       "\n",
       "                        Job Company       Job Location  Company Rating  \\\n",
       "0                            Indeed  San Francisco, CA             4.3   \n",
       "1                              Uber  San Francisco, CA             4.0   \n",
       "2                    JM Talent Inc.        Oakland, CA             0.0   \n",
       "3                Excelon Associates       Berkeley, CA             4.8   \n",
       "4                    Warman O'Brien  San Francisco, CA             5.0   \n",
       "...                             ...                ...             ...   \n",
       "5656                       Canalyst          Vancouver             3.3   \n",
       "5657                        Prenuvo          Vancouver             5.0   \n",
       "5658  WELL Health Technologies Corp          Vancouver             2.8   \n",
       "5659                MPM Engineering             Surrey             0.0   \n",
       "5660      postalong technology inc.           Richmond             0.0   \n",
       "\n",
       "      Company Rating Numbers         Company Size  Company Founded  \\\n",
       "0                        703     10000+ Employees             2004   \n",
       "1                       3142     10000+ Employees             2009   \n",
       "2                          0              Unknown                0   \n",
       "3                          1    1 to 50 Employees             2007   \n",
       "4                          0    1 to 50 Employees             2017   \n",
       "...                      ...                  ...              ...   \n",
       "5656                       8  51 to 200 Employees                0   \n",
       "5657                       4    1 to 50 Employees                0   \n",
       "5658                       0              Unknown                0   \n",
       "5659                       0              Unknown                0   \n",
       "5660                       0              Unknown                0   \n",
       "\n",
       "           Company Type                         Company Industry  \\\n",
       "0     Company - Private                                 Internet   \n",
       "1      Company - Public                                 Internet   \n",
       "2      Company - Public                                  Unknown   \n",
       "3     Company - Private                   Staffing & Outsourcing   \n",
       "4     Company - Private                   Staffing & Outsourcing   \n",
       "...                 ...                                      ...   \n",
       "5656            Unknown  Enterprise Software & Network Solutions   \n",
       "5657  Company - Private         Health Care Services & Hospitals   \n",
       "5658  Company - Private                                  Unknown   \n",
       "5659  Company - Private                                  Unknown   \n",
       "5660            Unknown                                  Unknown   \n",
       "\n",
       "              Company Sector             Company Revenue   Level   Minimum  \\\n",
       "0     Information Technology      $2 to $5 billion (USD)  Senior  153000.0   \n",
       "1     Information Technology          $10+ billion (USD)  Normal   87000.0   \n",
       "2                    Unknown    Unknown / Non-Applicable  Senior  100000.0   \n",
       "3          Business Services  Less than $1 million (USD)  Normal   62000.0   \n",
       "4          Business Services     $5 to $10 million (USD)  Normal  120000.0   \n",
       "...                      ...                         ...     ...       ...   \n",
       "5656  Information Technology    Unknown / Non-Applicable  Normal   72000.0   \n",
       "5657             Health Care    Unknown / Non-Applicable  Normal   81000.0   \n",
       "5658                 Unknown    Unknown / Non-Applicable  Normal   80000.0   \n",
       "5659                 Unknown    Unknown / Non-Applicable  Normal   53000.0   \n",
       "5660                 Unknown                     Unknown  Normal   99840.0   \n",
       "\n",
       "       Maximum Currency           Category Company               Role  \n",
       "0     223000.0      USD       Data Science      NaN      Data Science  \n",
       "1     167000.0      USD       Data Science      NaN      Data Analyst  \n",
       "2     100000.0      USD       Data Science      NaN      Data Analyst  \n",
       "3     162000.0      USD       Data Science      NaN      Data Science  \n",
       "4     140000.0      USD       Data Science      NaN      Data Science  \n",
       "...        ...      ...                ...      ...               ...  \n",
       "5656  100000.0       CA  Software Engineer      NaN               SWE  \n",
       "5657  117000.0       CA  Software Engineer      NaN  Infra/System SWE  \n",
       "5658  119000.0       CA  Software Engineer      NaN               SWE  \n",
       "5659   89000.0       CA  Software Engineer      NaN        Full Stack  \n",
       "5660   99840.0       CA  Software Engineer      NaN               SWE  \n",
       "\n",
       "[5661 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df = pd.read_csv(\"EDA_data_result.csv\")\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b865411a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Rating</th>\n",
       "      <th>Company Rating Numbers</th>\n",
       "      <th>Company Founded</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Job Location_Alameda, CA</th>\n",
       "      <th>Job Location_Berkeley, CA</th>\n",
       "      <th>Job Location_Brampton</th>\n",
       "      <th>Job Location_Bronx, NY</th>\n",
       "      <th>Job Location_Brooklyn, NY</th>\n",
       "      <th>...</th>\n",
       "      <th>Role_Data Researcher</th>\n",
       "      <th>Role_Data SWE</th>\n",
       "      <th>Role_Data Science</th>\n",
       "      <th>Role_FrontEnd</th>\n",
       "      <th>Role_Full Stack</th>\n",
       "      <th>Role_General Data</th>\n",
       "      <th>Role_Infra/System SWE</th>\n",
       "      <th>Role_Machine Learning</th>\n",
       "      <th>Role_SWE</th>\n",
       "      <th>Role_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.3</td>\n",
       "      <td>703</td>\n",
       "      <td>2004</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>223000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3142</td>\n",
       "      <td>2009</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>167000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company Rating  Company Rating Numbers  Company Founded   Minimum  \\\n",
       "0             4.3                     703             2004  153000.0   \n",
       "1             4.0                    3142             2009   87000.0   \n",
       "2             0.0                       0                0  100000.0   \n",
       "3             4.8                       1             2007   62000.0   \n",
       "4             5.0                       0             2017  120000.0   \n",
       "\n",
       "    Maximum  Job Location_Alameda, CA  Job Location_Berkeley, CA  \\\n",
       "0  223000.0                         0                          0   \n",
       "1  167000.0                         0                          0   \n",
       "2  100000.0                         0                          0   \n",
       "3  162000.0                         0                          1   \n",
       "4  140000.0                         0                          0   \n",
       "\n",
       "   Job Location_Brampton  Job Location_Bronx, NY  Job Location_Brooklyn, NY  \\\n",
       "0                      0                       0                          0   \n",
       "1                      0                       0                          0   \n",
       "2                      0                       0                          0   \n",
       "3                      0                       0                          0   \n",
       "4                      0                       0                          0   \n",
       "\n",
       "   ...  Role_Data Researcher  Role_Data SWE  Role_Data Science  Role_FrontEnd  \\\n",
       "0  ...                     0              0                  1              0   \n",
       "1  ...                     0              0                  0              0   \n",
       "2  ...                     0              0                  0              0   \n",
       "3  ...                     0              0                  1              0   \n",
       "4  ...                     0              0                  1              0   \n",
       "\n",
       "   Role_Full Stack  Role_General Data  Role_Infra/System SWE  \\\n",
       "0                0                  0                      0   \n",
       "1                0                  0                      0   \n",
       "2                0                  0                      0   \n",
       "3                0                  0                      0   \n",
       "4                0                  0                      0   \n",
       "\n",
       "   Role_Machine Learning  Role_SWE  Role_Test  \n",
       "0                      0         0          0  \n",
       "1                      0         0          0  \n",
       "2                      0         0          0  \n",
       "3                      0         0          0  \n",
       "4                      0         0          0  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dummy value from categorical data\n",
    "df_model = jobs_df[[\"Job Location\", \"Company Rating\", \"Company Rating Numbers\", \"Company Size\", \"Company Founded\", \"Company Type\", \n",
    "                    \"Company Industry\", \"Company Sector\", \"Company Revenue\", \"Level\", \"Minimum\", \"Maximum\", \"Currency\", \"Role\"]]\n",
    "df_dum = pd.get_dummies(df_model)\n",
    "df_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d10a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Minimum   Maximum\n",
      "687   136000.0  170000.0\n",
      "2680   90000.0  110000.0\n",
      "1513   68000.0  124000.0\n",
      "858    97000.0  189000.0\n",
      "2487   98000.0  119000.0\n",
      "...        ...       ...\n",
      "1892  131000.0  143000.0\n",
      "3502  185120.0  185120.0\n",
      "3715  160000.0  200000.0\n",
      "2438   74000.0  126000.0\n",
      "1230   89000.0  170000.0\n",
      "\n",
      "[1133 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# split to training and test data\n",
    "X = df_dum.drop(columns = [\"Minimum\", \"Maximum\"])\n",
    "y = df_dum[[\"Minimum\", \"Maximum\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fdcf3630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Minimum</td>     <th>  R-squared:         </th> <td>   0.702</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.692</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   67.90</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 21 Nov 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:05:53</td>     <th>  Log-Likelihood:    </th> <td> -51850.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4528</td>      <th>  AIC:               </th> <td>1.040e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4375</td>      <th>  BIC:               </th> <td>1.050e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   152</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                              <td></td>                                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                                     <td> 1.881e+04</td> <td> 3745.814</td> <td>    5.021</td> <td> 0.000</td> <td> 1.15e+04</td> <td> 2.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Rating</th>                                            <td> 1852.4882</td> <td>  650.761</td> <td>    2.847</td> <td> 0.004</td> <td>  576.667</td> <td> 3128.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Rating Numbers</th>                                    <td>    0.3510</td> <td>    0.452</td> <td>    0.776</td> <td> 0.438</td> <td>   -0.536</td> <td>    1.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Founded</th>                                           <td>   -6.8569</td> <td>    1.265</td> <td>   -5.419</td> <td> 0.000</td> <td>   -9.337</td> <td>   -4.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Alameda, CA</th>                                  <td>-4052.2530</td> <td> 1.66e+04</td> <td>   -0.244</td> <td> 0.807</td> <td>-3.66e+04</td> <td> 2.85e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Berkeley, CA</th>                                 <td>-4.855e+04</td> <td> 7124.329</td> <td>   -6.814</td> <td> 0.000</td> <td>-6.25e+04</td> <td>-3.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Brampton</th>                                     <td> 1.045e+04</td> <td> 1.74e+04</td> <td>    0.602</td> <td> 0.547</td> <td>-2.36e+04</td> <td> 4.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Bronx, NY</th>                                    <td>-1.066e+04</td> <td> 7594.912</td> <td>   -1.403</td> <td> 0.161</td> <td>-2.55e+04</td> <td> 4231.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Brooklyn, NY</th>                                 <td>-3.428e+04</td> <td> 5829.467</td> <td>   -5.881</td> <td> 0.000</td> <td>-4.57e+04</td> <td>-2.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Burlingame, CA</th>                               <td> 3.255e+04</td> <td> 6517.124</td> <td>    4.995</td> <td> 0.000</td> <td> 1.98e+04</td> <td> 4.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Burnaby</th>                                      <td>-1.234e+04</td> <td> 5393.516</td> <td>   -2.289</td> <td> 0.022</td> <td>-2.29e+04</td> <td>-1770.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_California</th>                                   <td>-9861.7836</td> <td> 5139.638</td> <td>   -1.919</td> <td> 0.055</td> <td>-1.99e+04</td> <td>  214.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Canada</th>                                       <td>-2.881e+04</td> <td> 1.61e+04</td> <td>   -1.789</td> <td> 0.074</td> <td>-6.04e+04</td> <td> 2763.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Delta</th>                                        <td>-1.249e+04</td> <td> 1.63e+04</td> <td>   -0.766</td> <td> 0.444</td> <td>-4.45e+04</td> <td> 1.95e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Edgewater, NJ</th>                                <td>-1.596e+04</td> <td>  2.4e+04</td> <td>   -0.665</td> <td> 0.506</td> <td> -6.3e+04</td> <td> 3.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Etobicoke</th>                                    <td> 4742.6935</td> <td> 1.63e+04</td> <td>    0.291</td> <td> 0.771</td> <td>-2.72e+04</td> <td> 3.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Greenvale, NY</th>                                <td>-4.628e+04</td> <td>  2.4e+04</td> <td>   -1.929</td> <td> 0.054</td> <td>-9.33e+04</td> <td>  744.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Jersey City, NJ</th>                              <td>-1.669e+04</td> <td> 1.39e+04</td> <td>   -1.201</td> <td> 0.230</td> <td>-4.39e+04</td> <td> 1.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Lake Success, NY</th>                             <td> 3.213e+04</td> <td> 2.37e+04</td> <td>    1.355</td> <td> 0.175</td> <td>-1.43e+04</td> <td> 7.86e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Langley</th>                                      <td> 1.712e+04</td> <td> 8093.656</td> <td>    2.115</td> <td> 0.034</td> <td> 1249.280</td> <td>  3.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Long Island City, NY</th>                         <td> 3.036e+04</td> <td> 1.49e+04</td> <td>    2.035</td> <td> 0.042</td> <td> 1104.656</td> <td> 5.96e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Markham</th>                                      <td>-4.743e+04</td> <td> 1.62e+04</td> <td>   -2.924</td> <td> 0.003</td> <td>-7.92e+04</td> <td>-1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Martinez, CA</th>                                 <td> 1.352e+04</td> <td> 8847.858</td> <td>    1.528</td> <td> 0.127</td> <td>-3827.719</td> <td> 3.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Menlo Park, CA</th>                               <td>-2.921e+04</td> <td> 1.33e+04</td> <td>   -2.192</td> <td> 0.028</td> <td>-5.53e+04</td> <td>-3090.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Midtown Toronto</th>                              <td> 3.323e+04</td> <td> 1.35e+04</td> <td>    2.458</td> <td> 0.014</td> <td> 6721.767</td> <td> 5.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Mississauga</th>                                  <td> 8077.9241</td> <td> 5231.608</td> <td>    1.544</td> <td> 0.123</td> <td>-2178.677</td> <td> 1.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Mississauga Valley</th>                           <td> 2.821e+04</td> <td> 9835.719</td> <td>    2.868</td> <td> 0.004</td> <td> 8930.622</td> <td> 4.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_New Hyde Park, NY</th>                            <td> 4.935e+04</td> <td> 2.38e+04</td> <td>    2.073</td> <td> 0.038</td> <td> 2688.975</td> <td>  9.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_New Westminster</th>                              <td>-7099.9318</td> <td> 2.27e+04</td> <td>   -0.313</td> <td> 0.755</td> <td>-5.16e+04</td> <td> 3.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_New York State</th>                               <td> 6.595e+04</td> <td> 7597.302</td> <td>    8.681</td> <td> 0.000</td> <td> 5.11e+04</td> <td> 8.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_New York, NY</th>                                 <td> 1.189e+04</td> <td> 3267.059</td> <td>    3.638</td> <td> 0.000</td> <td> 5481.856</td> <td> 1.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Newark, NJ</th>                                   <td>-1.332e+04</td> <td> 7433.941</td> <td>   -1.791</td> <td> 0.073</td> <td>-2.79e+04</td> <td> 1258.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_North Hills, NY</th>                              <td>-1.847e+04</td> <td> 1.64e+04</td> <td>   -1.128</td> <td> 0.259</td> <td>-5.06e+04</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_North Vancouver</th>                              <td> 1.513e+04</td> <td> 7073.305</td> <td>    2.139</td> <td> 0.032</td> <td> 1265.438</td> <td>  2.9e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_North York</th>                                   <td> 1.939e+04</td> <td> 1.19e+04</td> <td>    1.626</td> <td> 0.104</td> <td>-3987.653</td> <td> 4.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Oakland, CA</th>                                  <td> 3.763e+04</td> <td> 9187.743</td> <td>    4.096</td> <td> 0.000</td> <td> 1.96e+04</td> <td> 5.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Oakville</th>                                     <td> 2.556e+04</td> <td> 6340.298</td> <td>    4.032</td> <td> 0.000</td> <td> 1.31e+04</td> <td>  3.8e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Oceanside, NY</th>                                <td>-2.696e+04</td> <td>  2.4e+04</td> <td>   -1.123</td> <td> 0.262</td> <td> -7.4e+04</td> <td> 2.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Pearl River, NY</th>                              <td>   1.4e+04</td> <td> 2.27e+04</td> <td>    0.618</td> <td> 0.537</td> <td>-3.04e+04</td> <td> 5.84e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Queens Village, NY</th>                           <td>-3.267e+04</td> <td> 1.34e+04</td> <td>   -2.434</td> <td> 0.015</td> <td> -5.9e+04</td> <td>-6359.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Richmond</th>                                     <td> 9835.9680</td> <td> 5841.042</td> <td>    1.684</td> <td> 0.092</td> <td>-1615.431</td> <td> 2.13e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Richmond Hill</th>                                <td> -266.2160</td> <td>  2.4e+04</td> <td>   -0.011</td> <td> 0.991</td> <td>-4.72e+04</td> <td> 4.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_San Francisco, CA</th>                            <td> 3.123e+04</td> <td> 3283.772</td> <td>    9.509</td> <td> 0.000</td> <td> 2.48e+04</td> <td> 3.77e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_San Mateo, CA</th>                                <td> 2.988e+04</td> <td> 2.27e+04</td> <td>    1.315</td> <td> 0.189</td> <td>-1.47e+04</td> <td> 7.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Scarborough</th>                                  <td>    -7e+04</td> <td> 2.44e+04</td> <td>   -2.868</td> <td> 0.004</td> <td>-1.18e+05</td> <td>-2.22e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Staten Island, NY</th>                            <td>   73.1990</td> <td> 8893.323</td> <td>    0.008</td> <td> 0.993</td> <td>-1.74e+04</td> <td> 1.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Surrey</th>                                       <td>-1.378e+04</td> <td> 6677.440</td> <td>   -2.064</td> <td> 0.039</td> <td>-2.69e+04</td> <td> -688.677</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Toronto</th>                                      <td> 5810.9327</td> <td> 3899.078</td> <td>    1.490</td> <td> 0.136</td> <td>-1833.234</td> <td> 1.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Vancouver</th>                                    <td> 5537.3130</td> <td> 3948.370</td> <td>    1.402</td> <td> 0.161</td> <td>-2203.491</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Vaughan</th>                                      <td> -1.49e+04</td> <td> 1.34e+04</td> <td>   -1.110</td> <td> 0.267</td> <td>-4.12e+04</td> <td> 1.14e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_White Plains, NY</th>                             <td>-2.677e+04</td> <td> 7255.660</td> <td>   -3.690</td> <td> 0.000</td> <td> -4.1e+04</td> <td>-1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Job Location_Woodbridge</th>                                   <td> 2.802e+04</td> <td> 3.27e+04</td> <td>    0.858</td> <td> 0.391</td> <td> -3.6e+04</td> <td> 9.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Size_1 to 50 Employees</th>                            <td>-1.359e+04</td> <td> 1705.855</td> <td>   -7.966</td> <td> 0.000</td> <td>-1.69e+04</td> <td>-1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Size_10000+ Employees</th>                             <td> 7755.7773</td> <td> 2073.551</td> <td>    3.740</td> <td> 0.000</td> <td> 3690.567</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Size_1001 to 5000 Employees</th>                       <td> 1.269e+04</td> <td> 1998.893</td> <td>    6.348</td> <td> 0.000</td> <td> 8769.715</td> <td> 1.66e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Size_201 to 500 Employees</th>                         <td> 9072.7522</td> <td> 2330.126</td> <td>    3.894</td> <td> 0.000</td> <td> 4504.526</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Size_5001 to 10000 Employees</th>                      <td> 4801.5779</td> <td> 2518.868</td> <td>    1.906</td> <td> 0.057</td> <td> -136.679</td> <td> 9739.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Size_501 to 1000 Employees</th>                        <td> 1.464e+04</td> <td> 1781.869</td> <td>    8.218</td> <td> 0.000</td> <td> 1.11e+04</td> <td> 1.81e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Size_51 to 200 Employees</th>                          <td> 7965.3273</td> <td> 2072.492</td> <td>    3.843</td> <td> 0.000</td> <td> 3902.193</td> <td>  1.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Size_Unknown</th>                                      <td>-2.453e+04</td> <td> 3688.286</td> <td>   -6.651</td> <td> 0.000</td> <td>-3.18e+04</td> <td>-1.73e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_College / University</th>                         <td>-1.423e+05</td> <td> 2.02e+04</td> <td>   -7.058</td> <td> 0.000</td> <td>-1.82e+05</td> <td>-1.03e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Company - Private</th>                            <td> 2.032e+04</td> <td> 4034.436</td> <td>    5.037</td> <td> 0.000</td> <td> 1.24e+04</td> <td> 2.82e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Company - Public</th>                             <td> 9104.7629</td> <td> 4067.998</td> <td>    2.238</td> <td> 0.025</td> <td> 1129.427</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Franchise</th>                                    <td> 2.821e+04</td> <td> 9835.719</td> <td>    2.868</td> <td> 0.004</td> <td> 8930.622</td> <td> 4.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Government</th>                                   <td> 2.668e+04</td> <td> 1.45e+04</td> <td>    1.843</td> <td> 0.065</td> <td>-1703.814</td> <td> 5.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Hospital</th>                                     <td>-1.135e+04</td> <td> 7896.808</td> <td>   -1.437</td> <td> 0.151</td> <td>-2.68e+04</td> <td> 4134.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Nonprofit Organization</th>                       <td>-3.392e+04</td> <td> 7005.024</td> <td>   -4.842</td> <td> 0.000</td> <td>-4.77e+04</td> <td>-2.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Private Practice / Firm</th>                      <td> 2.545e+04</td> <td> 9234.821</td> <td>    2.755</td> <td> 0.006</td> <td> 7340.337</td> <td> 4.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Self-employed</th>                                <td> 7.618e+04</td> <td> 2.68e+04</td> <td>    2.846</td> <td> 0.004</td> <td> 2.37e+04</td> <td> 1.29e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Subsidiary or Business Segment</th>               <td> 7092.4363</td> <td> 4638.752</td> <td>    1.529</td> <td> 0.126</td> <td>-2001.867</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Type_Unknown</th>                                      <td> 1.333e+04</td> <td> 5272.209</td> <td>    2.528</td> <td> 0.012</td> <td> 2989.785</td> <td> 2.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Accounting</th>                               <td>-7283.7035</td> <td> 8394.986</td> <td>   -0.868</td> <td> 0.386</td> <td>-2.37e+04</td> <td> 9174.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Advertising & Marketing</th>                  <td> 2.651e+04</td> <td> 5342.917</td> <td>    4.962</td> <td> 0.000</td> <td>  1.6e+04</td> <td>  3.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Aerospace & Defense</th>                      <td> 2399.8221</td> <td> 9173.686</td> <td>    0.262</td> <td> 0.794</td> <td>-1.56e+04</td> <td> 2.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Banks & Credit Unions</th>                    <td> 6251.9910</td> <td> 6687.258</td> <td>    0.935</td> <td> 0.350</td> <td>-6858.420</td> <td> 1.94e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Biotech & Pharmaceuticals</th>                <td> 1521.0290</td> <td> 3763.962</td> <td>    0.404</td> <td> 0.686</td> <td>-5858.242</td> <td> 8900.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Cable, Internet & Telephone Providers</th>    <td> 3.162e+04</td> <td> 4810.530</td> <td>    6.573</td> <td> 0.000</td> <td> 2.22e+04</td> <td>  4.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Colleges & Universities</th>                  <td> 7.225e+04</td> <td> 1.61e+04</td> <td>    4.481</td> <td> 0.000</td> <td> 4.06e+04</td> <td> 1.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Commercial Equipment Rental</th>              <td> 3.316e+04</td> <td> 6434.124</td> <td>    5.154</td> <td> 0.000</td> <td> 2.05e+04</td> <td> 4.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Computer Hardware & Software</th>             <td> 5867.9860</td> <td> 1687.761</td> <td>    3.477</td> <td> 0.001</td> <td> 2559.120</td> <td> 9176.852</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Consulting</th>                               <td>-3832.8538</td> <td> 4216.804</td> <td>   -0.909</td> <td> 0.363</td> <td>-1.21e+04</td> <td> 4434.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Consumer Electronics & Appliances Stores</th> <td> 8959.2107</td> <td> 8747.243</td> <td>    1.024</td> <td> 0.306</td> <td>-8189.816</td> <td> 2.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Consumer Products Manufacturing</th>          <td>-2.946e+04</td> <td> 6906.921</td> <td>   -4.265</td> <td> 0.000</td> <td> -4.3e+04</td> <td>-1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Department, Clothing, & Shoe Stores</th>      <td>-2.488e+04</td> <td> 7772.852</td> <td>   -3.201</td> <td> 0.001</td> <td>-4.01e+04</td> <td>-9643.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Education Training Services</th>              <td>-2.718e+04</td> <td> 1.71e+04</td> <td>   -1.588</td> <td> 0.112</td> <td>-6.07e+04</td> <td> 6380.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Electrical & Electronic Manufacturing</th>    <td> 1.275e+04</td> <td> 1.01e+04</td> <td>    1.263</td> <td> 0.207</td> <td>-7040.274</td> <td> 3.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Energy</th>                                   <td>-1.887e+04</td> <td> 1.07e+04</td> <td>   -1.761</td> <td> 0.078</td> <td>-3.99e+04</td> <td> 2136.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Enterprise Software & Network Solutions</th>  <td>  673.5855</td> <td> 1725.584</td> <td>    0.390</td> <td> 0.696</td> <td>-2709.433</td> <td> 4056.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Express Delivery Services</th>                <td>-3.414e+04</td> <td> 1.29e+04</td> <td>   -2.655</td> <td> 0.008</td> <td>-5.93e+04</td> <td>-8932.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Farm Support Services</th>                    <td>  1.38e+04</td> <td> 2764.672</td> <td>    4.990</td> <td> 0.000</td> <td> 8375.912</td> <td> 1.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Federal Agencies</th>                         <td> 3.576e+04</td> <td> 1.09e+04</td> <td>    3.267</td> <td> 0.001</td> <td> 1.43e+04</td> <td> 5.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Financial Analytics & Research</th>           <td>-4489.9067</td> <td> 2.23e+04</td> <td>   -0.202</td> <td> 0.840</td> <td>-4.81e+04</td> <td> 3.91e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Financial Transaction Processing</th>         <td>-2.646e+04</td> <td> 7087.952</td> <td>   -3.733</td> <td> 0.000</td> <td>-4.04e+04</td> <td>-1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Food & Beverage Manufacturing</th>            <td>-2.539e+04</td> <td> 7731.981</td> <td>   -3.283</td> <td> 0.001</td> <td>-4.05e+04</td> <td>-1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Grocery Stores & Supermarkets</th>            <td>-8.239e+04</td> <td> 1.09e+04</td> <td>   -7.535</td> <td> 0.000</td> <td>-1.04e+05</td> <td> -6.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Health Care Services & Hospitals</th>         <td>-6917.0824</td> <td> 2669.365</td> <td>   -2.591</td> <td> 0.010</td> <td>-1.22e+04</td> <td>-1683.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Home Centers & Hardware Stores</th>           <td> 2.496e+04</td> <td> 1.33e+04</td> <td>    1.880</td> <td> 0.060</td> <td>-1066.387</td> <td>  5.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Home Furniture & Housewares Stores</th>       <td>-2.254e+04</td> <td> 1.07e+04</td> <td>   -2.112</td> <td> 0.035</td> <td>-4.35e+04</td> <td>-1613.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Hotels, Motels, & Resorts</th>                <td> 1.087e-10</td> <td> 3.75e-10</td> <td>    0.290</td> <td> 0.772</td> <td>-6.27e-10</td> <td> 8.44e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_IT Services</th>                              <td> -1.51e+04</td> <td> 2056.427</td> <td>   -7.341</td> <td> 0.000</td> <td>-1.91e+04</td> <td>-1.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Industrial Manufacturing</th>                 <td> 8369.6793</td> <td> 2.37e+04</td> <td>    0.353</td> <td> 0.724</td> <td>-3.81e+04</td> <td> 5.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Insurance Agencies & Brokerages</th>          <td>-2.671e+04</td> <td> 3315.340</td> <td>   -8.058</td> <td> 0.000</td> <td>-3.32e+04</td> <td>-2.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Insurance Carriers</th>                       <td> 2.583e+04</td> <td> 3131.703</td> <td>    8.246</td> <td> 0.000</td> <td> 1.97e+04</td> <td>  3.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Internet</th>                                 <td> 7623.7241</td> <td> 1228.329</td> <td>    6.207</td> <td> 0.000</td> <td> 5215.577</td> <td>    1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Investment Banking & Asset Management</th>    <td> 1.602e+04</td> <td> 6420.880</td> <td>    2.495</td> <td> 0.013</td> <td> 3432.855</td> <td> 2.86e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Logistics & Supply Chain</th>                 <td>-5157.1641</td> <td> 1.98e+04</td> <td>   -0.261</td> <td> 0.794</td> <td>-4.39e+04</td> <td> 3.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Membership Organizations</th>                 <td>-1.941e+04</td> <td> 4190.469</td> <td>   -4.632</td> <td> 0.000</td> <td>-2.76e+04</td> <td>-1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Miscellaneous Manufacturing</th>              <td> 5397.1011</td> <td> 2.04e+04</td> <td>    0.264</td> <td> 0.791</td> <td>-3.46e+04</td> <td> 4.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Motion Picture Production & Distribution</th> <td>  2.07e+04</td> <td> 6873.058</td> <td>    3.011</td> <td> 0.003</td> <td> 7221.971</td> <td> 3.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Municipal Governments</th>                    <td>-1.759e+04</td> <td> 1.66e+04</td> <td>   -1.063</td> <td> 0.288</td> <td>   -5e+04</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_News Outlet</th>                              <td>-1.561e+04</td> <td> 7811.449</td> <td>   -1.999</td> <td> 0.046</td> <td>-3.09e+04</td> <td> -300.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Oil & Gas Services</th>                       <td>-9153.9274</td> <td> 1.84e+04</td> <td>   -0.498</td> <td> 0.618</td> <td>-4.52e+04</td> <td> 2.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Other Retail Stores</th>                      <td> 6.584e+04</td> <td> 1.72e+04</td> <td>    3.823</td> <td> 0.000</td> <td> 3.21e+04</td> <td> 9.96e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Publishing</th>                               <td> 2.023e+04</td> <td> 2.05e+04</td> <td>    0.985</td> <td> 0.325</td> <td>   -2e+04</td> <td> 6.05e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Real Estate</th>                              <td>-4057.8460</td> <td> 8089.019</td> <td>   -0.502</td> <td> 0.616</td> <td>-1.99e+04</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Research & Development</th>                   <td>-5.502e+04</td> <td> 1.47e+04</td> <td>   -3.738</td> <td> 0.000</td> <td>-8.39e+04</td> <td>-2.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Shipping</th>                                 <td> 4.893e+04</td> <td> 1.03e+04</td> <td>    4.736</td> <td> 0.000</td> <td> 2.87e+04</td> <td> 6.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Social Assistance</th>                        <td> 7260.4811</td> <td> 5047.622</td> <td>    1.438</td> <td> 0.150</td> <td>-2635.415</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Staffing & Outsourcing</th>                   <td> 4.598e+04</td> <td> 3290.571</td> <td>   13.973</td> <td> 0.000</td> <td> 3.95e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_TV Broadcast & Cable Networks</th>            <td>-1.395e+04</td> <td> 1.09e+04</td> <td>   -1.281</td> <td> 0.200</td> <td>-3.53e+04</td> <td> 7392.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Telecommunications Manufacturing</th>         <td>-2.983e+04</td> <td> 6664.829</td> <td>   -4.476</td> <td> 0.000</td> <td>-4.29e+04</td> <td>-1.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Telecommunications Services</th>              <td>-2580.7330</td> <td> 3988.119</td> <td>   -0.647</td> <td> 0.518</td> <td>-1.04e+04</td> <td> 5237.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Transportation Equipment Manufacturing</th>   <td> 1.733e+04</td> <td> 8647.500</td> <td>    2.004</td> <td> 0.045</td> <td>  379.357</td> <td> 3.43e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Transportation Management</th>                <td>-2.254e+04</td> <td> 2.49e+04</td> <td>   -0.905</td> <td> 0.365</td> <td>-7.14e+04</td> <td> 2.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Travel Agencies</th>                          <td> 9.891e-11</td> <td> 2.64e-10</td> <td>    0.375</td> <td> 0.708</td> <td>-4.19e-10</td> <td> 6.16e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Unknown</th>                                  <td> 3.833e+04</td> <td> 1.87e+04</td> <td>    2.047</td> <td> 0.041</td> <td> 1615.502</td> <td>  7.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Utilities</th>                                <td> 2.088e+04</td> <td> 1.01e+04</td> <td>    2.062</td> <td> 0.039</td> <td> 1028.230</td> <td> 4.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Vehicle Dealers</th>                          <td>-2.423e+04</td> <td> 1.93e+04</td> <td>   -1.254</td> <td> 0.210</td> <td>-6.21e+04</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Video Games</th>                              <td>-1.024e+04</td> <td> 6148.224</td> <td>   -1.666</td> <td> 0.096</td> <td>-2.23e+04</td> <td> 1811.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Industry_Wholesale</th>                                <td>-2.138e+04</td> <td> 1.16e+04</td> <td>   -1.850</td> <td> 0.064</td> <td> -4.4e+04</td> <td> 1271.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Accounting & Legal</th>                         <td>-7283.7035</td> <td> 8394.986</td> <td>   -0.868</td> <td> 0.386</td> <td>-2.37e+04</td> <td> 9174.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Aerospace & Defense</th>                        <td> 2399.8221</td> <td> 9173.686</td> <td>    0.262</td> <td> 0.794</td> <td>-1.56e+04</td> <td> 2.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Agriculture & Forestry</th>                     <td>  1.38e+04</td> <td> 2764.672</td> <td>    4.990</td> <td> 0.000</td> <td> 8375.912</td> <td> 1.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Biotech & Pharmaceuticals</th>                  <td> 1521.0290</td> <td> 3763.962</td> <td>    0.404</td> <td> 0.686</td> <td>-5858.242</td> <td> 8900.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Business Services</th>                          <td> 6012.5949</td> <td> 2960.300</td> <td>    2.031</td> <td> 0.042</td> <td>  208.908</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Education</th>                                  <td> 4.508e+04</td> <td> 9992.218</td> <td>    4.511</td> <td> 0.000</td> <td> 2.55e+04</td> <td> 6.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Finance</th>                                    <td>-8672.8445</td> <td> 5381.508</td> <td>   -1.612</td> <td> 0.107</td> <td>-1.92e+04</td> <td> 1877.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Government</th>                                 <td> 1.817e+04</td> <td> 1.25e+04</td> <td>    1.457</td> <td> 0.145</td> <td>-6282.710</td> <td> 4.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Health Care</th>                                <td>-6917.0824</td> <td> 2669.365</td> <td>   -2.591</td> <td> 0.010</td> <td>-1.22e+04</td> <td>-1683.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Information Technology</th>                     <td> -931.5835</td> <td> 2315.693</td> <td>   -0.402</td> <td> 0.687</td> <td>-5471.513</td> <td> 3608.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Insurance</th>                                  <td> -888.9951</td> <td> 2558.785</td> <td>   -0.347</td> <td> 0.728</td> <td>-5905.510</td> <td> 4127.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Manufacturing</th>                              <td>  -1.1e+04</td> <td> 5643.717</td> <td>   -1.949</td> <td> 0.051</td> <td>-2.21e+04</td> <td>   66.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Media</th>                                      <td> 1119.9539</td> <td> 4921.544</td> <td>    0.228</td> <td> 0.820</td> <td>-8528.764</td> <td> 1.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Non-Profit</th>                                 <td> 7260.4811</td> <td> 5047.622</td> <td>    1.438</td> <td> 0.150</td> <td>-2635.415</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Oil, Gas, Energy & Utilities</th>               <td>-7140.4165</td> <td> 6650.018</td> <td>   -1.074</td> <td> 0.283</td> <td>-2.02e+04</td> <td> 5896.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Real Estate</th>                                <td>-4057.8460</td> <td> 8089.019</td> <td>   -0.502</td> <td> 0.616</td> <td>-1.99e+04</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Retail</th>                                     <td>   1.4e+04</td> <td> 7466.230</td> <td>    1.875</td> <td> 0.061</td> <td> -640.743</td> <td> 2.86e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Telecommunications</th>                         <td> -791.2093</td> <td> 3226.489</td> <td>   -0.245</td> <td> 0.806</td> <td>-7116.762</td> <td> 5534.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Transportation & Logistics</th>                 <td>-1.291e+04</td> <td> 7651.875</td> <td>   -1.687</td> <td> 0.092</td> <td>-2.79e+04</td> <td> 2093.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Travel & Tourism</th>                           <td>  1.37e-12</td> <td> 4.08e-12</td> <td>    0.336</td> <td> 0.737</td> <td>-6.63e-12</td> <td> 9.37e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Sector_Unknown</th>                                    <td>-2.996e+04</td> <td> 1.79e+04</td> <td>   -1.675</td> <td> 0.094</td> <td> -6.5e+04</td> <td> 5095.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$1 to $2 billion (USD)</th>                    <td> -1.87e+04</td> <td> 4928.056</td> <td>   -3.794</td> <td> 0.000</td> <td>-2.84e+04</td> <td>-9036.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$1 to $5 million (USD)</th>                    <td>-2.919e+04</td> <td> 3242.209</td> <td>   -9.004</td> <td> 0.000</td> <td>-3.56e+04</td> <td>-2.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$10 to $25 million (USD)</th>                  <td> 5565.0195</td> <td> 3577.117</td> <td>    1.556</td> <td> 0.120</td> <td>-1447.942</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$10+ billion (USD)</th>                        <td> 7023.1056</td> <td> 2816.680</td> <td>    2.493</td> <td> 0.013</td> <td> 1500.987</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$100 to $500 million (USD)</th>                <td>-2.453e+04</td> <td> 2443.612</td> <td>  -10.040</td> <td> 0.000</td> <td>-2.93e+04</td> <td>-1.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$2 to $5 billion (USD)</th>                    <td>  2.83e+04</td> <td> 2325.575</td> <td>   12.168</td> <td> 0.000</td> <td> 2.37e+04</td> <td> 3.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$25 to $50 million (USD)</th>                  <td> 8981.6019</td> <td> 2278.179</td> <td>    3.942</td> <td> 0.000</td> <td> 4515.217</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$5 to $10 billion (USD)</th>                   <td> 4264.1362</td> <td> 3045.118</td> <td>    1.400</td> <td> 0.161</td> <td>-1705.837</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$5 to $10 million (USD)</th>                   <td>-6438.4195</td> <td> 3999.080</td> <td>   -1.610</td> <td> 0.107</td> <td>-1.43e+04</td> <td> 1401.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$50 to $100 million (USD)</th>                 <td>-1.459e+04</td> <td> 4033.859</td> <td>   -3.616</td> <td> 0.000</td> <td>-2.25e+04</td> <td>-6676.730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_$500 million to $1 billion (USD)</th>          <td> 1.922e+04</td> <td> 5005.168</td> <td>    3.841</td> <td> 0.000</td> <td> 9411.333</td> <td>  2.9e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_Less than $1 million (USD)</th>                <td> 1.082e+04</td> <td> 3118.254</td> <td>    3.469</td> <td> 0.001</td> <td> 4705.248</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_Unknown</th>                                   <td> 2.525e+04</td> <td> 5005.555</td> <td>    5.045</td> <td> 0.000</td> <td> 1.54e+04</td> <td> 3.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Company Revenue_Unknown / Non-Applicable</th>                  <td> 2829.1431</td> <td> 1297.223</td> <td>    2.181</td> <td> 0.029</td> <td>  285.929</td> <td> 5372.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Level_Intern</th>                                              <td>-5.917e+04</td> <td> 1.57e+04</td> <td>   -3.758</td> <td> 0.000</td> <td>   -9e+04</td> <td>-2.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Level_Junior</th>                                              <td> 1.409e+04</td> <td> 4706.853</td> <td>    2.994</td> <td> 0.003</td> <td> 4863.724</td> <td> 2.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Level_Normal</th>                                              <td> 2.491e+04</td> <td> 4317.336</td> <td>    5.771</td> <td> 0.000</td> <td> 1.64e+04</td> <td> 3.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Level_Senior</th>                                              <td> 3.897e+04</td> <td> 4364.057</td> <td>    8.930</td> <td> 0.000</td> <td> 3.04e+04</td> <td> 4.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Currency_CA</th>                                               <td> 3985.2473</td> <td> 2822.265</td> <td>    1.412</td> <td> 0.158</td> <td>-1547.821</td> <td> 9518.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Currency_USD</th>                                              <td> 1.482e+04</td> <td> 3295.313</td> <td>    4.498</td> <td> 0.000</td> <td> 8361.417</td> <td> 2.13e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Artificial Intelligence</th>                              <td>-1.074e+04</td> <td> 4150.397</td> <td>   -2.588</td> <td> 0.010</td> <td>-1.89e+04</td> <td>-2605.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_BackEnd</th>                                              <td>  1.13e+04</td> <td> 2574.950</td> <td>    4.387</td> <td> 0.000</td> <td> 6247.433</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Data Analyst</th>                                         <td>-1.719e+04</td> <td> 1443.672</td> <td>  -11.910</td> <td> 0.000</td> <td>   -2e+04</td> <td>-1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Data Engineer</th>                                        <td>-1.002e+04</td> <td> 2101.829</td> <td>   -4.766</td> <td> 0.000</td> <td>-1.41e+04</td> <td>-5895.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Data Researcher</th>                                      <td>  1.07e+04</td> <td> 2794.934</td> <td>    3.828</td> <td> 0.000</td> <td> 5219.823</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Data SWE</th>                                             <td> -754.3193</td> <td> 3931.444</td> <td>   -0.192</td> <td> 0.848</td> <td>-8461.940</td> <td> 6953.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Data Science</th>                                         <td> -178.6542</td> <td> 1324.462</td> <td>   -0.135</td> <td> 0.893</td> <td>-2775.270</td> <td> 2417.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_FrontEnd</th>                                             <td> 8378.3593</td> <td> 2647.595</td> <td>    3.165</td> <td> 0.002</td> <td> 3187.732</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Full Stack</th>                                           <td> 1.279e+04</td> <td> 1462.183</td> <td>    8.750</td> <td> 0.000</td> <td> 9927.444</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_General Data</th>                                         <td> 3032.8051</td> <td> 5146.556</td> <td>    0.589</td> <td> 0.556</td> <td>-7057.052</td> <td> 1.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Infra/System SWE</th>                                     <td> 5952.0690</td> <td> 2975.286</td> <td>    2.001</td> <td> 0.046</td> <td>  119.002</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Machine Learning</th>                                     <td> 6877.8753</td> <td> 1678.679</td> <td>    4.097</td> <td> 0.000</td> <td> 3586.814</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_SWE</th>                                                  <td>  1.42e+04</td> <td> 1159.031</td> <td>   12.250</td> <td> 0.000</td> <td> 1.19e+04</td> <td> 1.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Role_Test</th>                                                 <td>-1.553e+04</td> <td> 5609.815</td> <td>   -2.769</td> <td> 0.006</td> <td>-2.65e+04</td> <td>-4536.586</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>220.265</td> <th>  Durbin-Watson:     </th> <td>   1.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 582.149</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.250</td>  <th>  Prob(JB):          </th> <td>3.87e-127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.684</td>  <th>  Cond. No.          </th> <td>1.92e+18</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.52e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                Minimum   R-squared:                       0.702\n",
       "Model:                            OLS   Adj. R-squared:                  0.692\n",
       "Method:                 Least Squares   F-statistic:                     67.90\n",
       "Date:                Sun, 21 Nov 2021   Prob (F-statistic):               0.00\n",
       "Time:                        11:05:53   Log-Likelihood:                -51850.\n",
       "No. Observations:                4528   AIC:                         1.040e+05\n",
       "Df Residuals:                    4375   BIC:                         1.050e+05\n",
       "Df Model:                         152                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================================================\n",
       "                                                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------------------\n",
       "const                                                      1.881e+04   3745.814      5.021      0.000    1.15e+04    2.62e+04\n",
       "Company Rating                                             1852.4882    650.761      2.847      0.004     576.667    3128.309\n",
       "Company Rating Numbers                                        0.3510      0.452      0.776      0.438      -0.536       1.238\n",
       "Company Founded                                              -6.8569      1.265     -5.419      0.000      -9.337      -4.376\n",
       "Job Location_Alameda, CA                                  -4052.2530   1.66e+04     -0.244      0.807   -3.66e+04    2.85e+04\n",
       "Job Location_Berkeley, CA                                 -4.855e+04   7124.329     -6.814      0.000   -6.25e+04   -3.46e+04\n",
       "Job Location_Brampton                                      1.045e+04   1.74e+04      0.602      0.547   -2.36e+04    4.45e+04\n",
       "Job Location_Bronx, NY                                    -1.066e+04   7594.912     -1.403      0.161   -2.55e+04    4231.003\n",
       "Job Location_Brooklyn, NY                                 -3.428e+04   5829.467     -5.881      0.000   -4.57e+04   -2.29e+04\n",
       "Job Location_Burlingame, CA                                3.255e+04   6517.124      4.995      0.000    1.98e+04    4.53e+04\n",
       "Job Location_Burnaby                                      -1.234e+04   5393.516     -2.289      0.022   -2.29e+04   -1770.128\n",
       "Job Location_California                                   -9861.7836   5139.638     -1.919      0.055   -1.99e+04     214.509\n",
       "Job Location_Canada                                       -2.881e+04   1.61e+04     -1.789      0.074   -6.04e+04    2763.879\n",
       "Job Location_Delta                                        -1.249e+04   1.63e+04     -0.766      0.444   -4.45e+04    1.95e+04\n",
       "Job Location_Edgewater, NJ                                -1.596e+04    2.4e+04     -0.665      0.506    -6.3e+04    3.11e+04\n",
       "Job Location_Etobicoke                                     4742.6935   1.63e+04      0.291      0.771   -2.72e+04    3.67e+04\n",
       "Job Location_Greenvale, NY                                -4.628e+04    2.4e+04     -1.929      0.054   -9.33e+04     744.568\n",
       "Job Location_Jersey City, NJ                              -1.669e+04   1.39e+04     -1.201      0.230   -4.39e+04    1.06e+04\n",
       "Job Location_Lake Success, NY                              3.213e+04   2.37e+04      1.355      0.175   -1.43e+04    7.86e+04\n",
       "Job Location_Langley                                       1.712e+04   8093.656      2.115      0.034    1249.280     3.3e+04\n",
       "Job Location_Long Island City, NY                          3.036e+04   1.49e+04      2.035      0.042    1104.656    5.96e+04\n",
       "Job Location_Markham                                      -4.743e+04   1.62e+04     -2.924      0.003   -7.92e+04   -1.56e+04\n",
       "Job Location_Martinez, CA                                  1.352e+04   8847.858      1.528      0.127   -3827.719    3.09e+04\n",
       "Job Location_Menlo Park, CA                               -2.921e+04   1.33e+04     -2.192      0.028   -5.53e+04   -3090.788\n",
       "Job Location_Midtown Toronto                               3.323e+04   1.35e+04      2.458      0.014    6721.767    5.97e+04\n",
       "Job Location_Mississauga                                   8077.9241   5231.608      1.544      0.123   -2178.677    1.83e+04\n",
       "Job Location_Mississauga Valley                            2.821e+04   9835.719      2.868      0.004    8930.622    4.75e+04\n",
       "Job Location_New Hyde Park, NY                             4.935e+04   2.38e+04      2.073      0.038    2688.975     9.6e+04\n",
       "Job Location_New Westminster                              -7099.9318   2.27e+04     -0.313      0.755   -5.16e+04    3.74e+04\n",
       "Job Location_New York State                                6.595e+04   7597.302      8.681      0.000    5.11e+04    8.08e+04\n",
       "Job Location_New York, NY                                  1.189e+04   3267.059      3.638      0.000    5481.856    1.83e+04\n",
       "Job Location_Newark, NJ                                   -1.332e+04   7433.941     -1.791      0.073   -2.79e+04    1258.719\n",
       "Job Location_North Hills, NY                              -1.847e+04   1.64e+04     -1.128      0.259   -5.06e+04    1.36e+04\n",
       "Job Location_North Vancouver                               1.513e+04   7073.305      2.139      0.032    1265.438     2.9e+04\n",
       "Job Location_North York                                    1.939e+04   1.19e+04      1.626      0.104   -3987.653    4.28e+04\n",
       "Job Location_Oakland, CA                                   3.763e+04   9187.743      4.096      0.000    1.96e+04    5.56e+04\n",
       "Job Location_Oakville                                      2.556e+04   6340.298      4.032      0.000    1.31e+04     3.8e+04\n",
       "Job Location_Oceanside, NY                                -2.696e+04    2.4e+04     -1.123      0.262    -7.4e+04    2.01e+04\n",
       "Job Location_Pearl River, NY                                 1.4e+04   2.27e+04      0.618      0.537   -3.04e+04    5.84e+04\n",
       "Job Location_Queens Village, NY                           -3.267e+04   1.34e+04     -2.434      0.015    -5.9e+04   -6359.642\n",
       "Job Location_Richmond                                      9835.9680   5841.042      1.684      0.092   -1615.431    2.13e+04\n",
       "Job Location_Richmond Hill                                 -266.2160    2.4e+04     -0.011      0.991   -4.72e+04    4.67e+04\n",
       "Job Location_San Francisco, CA                             3.123e+04   3283.772      9.509      0.000    2.48e+04    3.77e+04\n",
       "Job Location_San Mateo, CA                                 2.988e+04   2.27e+04      1.315      0.189   -1.47e+04    7.44e+04\n",
       "Job Location_Scarborough                                      -7e+04   2.44e+04     -2.868      0.004   -1.18e+05   -2.22e+04\n",
       "Job Location_Staten Island, NY                               73.1990   8893.323      0.008      0.993   -1.74e+04    1.75e+04\n",
       "Job Location_Surrey                                       -1.378e+04   6677.440     -2.064      0.039   -2.69e+04    -688.677\n",
       "Job Location_Toronto                                       5810.9327   3899.078      1.490      0.136   -1833.234    1.35e+04\n",
       "Job Location_Vancouver                                     5537.3130   3948.370      1.402      0.161   -2203.491    1.33e+04\n",
       "Job Location_Vaughan                                       -1.49e+04   1.34e+04     -1.110      0.267   -4.12e+04    1.14e+04\n",
       "Job Location_White Plains, NY                             -2.677e+04   7255.660     -3.690      0.000    -4.1e+04   -1.25e+04\n",
       "Job Location_Woodbridge                                    2.802e+04   3.27e+04      0.858      0.391    -3.6e+04    9.21e+04\n",
       "Company Size_1 to 50 Employees                            -1.359e+04   1705.855     -7.966      0.000   -1.69e+04   -1.02e+04\n",
       "Company Size_10000+ Employees                              7755.7773   2073.551      3.740      0.000    3690.567    1.18e+04\n",
       "Company Size_1001 to 5000 Employees                        1.269e+04   1998.893      6.348      0.000    8769.715    1.66e+04\n",
       "Company Size_201 to 500 Employees                          9072.7522   2330.126      3.894      0.000    4504.526    1.36e+04\n",
       "Company Size_5001 to 10000 Employees                       4801.5779   2518.868      1.906      0.057    -136.679    9739.835\n",
       "Company Size_501 to 1000 Employees                         1.464e+04   1781.869      8.218      0.000    1.11e+04    1.81e+04\n",
       "Company Size_51 to 200 Employees                           7965.3273   2072.492      3.843      0.000    3902.193     1.2e+04\n",
       "Company Size_Unknown                                      -2.453e+04   3688.286     -6.651      0.000   -3.18e+04   -1.73e+04\n",
       "Company Type_College / University                         -1.423e+05   2.02e+04     -7.058      0.000   -1.82e+05   -1.03e+05\n",
       "Company Type_Company - Private                             2.032e+04   4034.436      5.037      0.000    1.24e+04    2.82e+04\n",
       "Company Type_Company - Public                              9104.7629   4067.998      2.238      0.025    1129.427    1.71e+04\n",
       "Company Type_Franchise                                     2.821e+04   9835.719      2.868      0.004    8930.622    4.75e+04\n",
       "Company Type_Government                                    2.668e+04   1.45e+04      1.843      0.065   -1703.814    5.51e+04\n",
       "Company Type_Hospital                                     -1.135e+04   7896.808     -1.437      0.151   -2.68e+04    4134.437\n",
       "Company Type_Nonprofit Organization                       -3.392e+04   7005.024     -4.842      0.000   -4.77e+04   -2.02e+04\n",
       "Company Type_Private Practice / Firm                       2.545e+04   9234.821      2.755      0.006    7340.337    4.36e+04\n",
       "Company Type_Self-employed                                 7.618e+04   2.68e+04      2.846      0.004    2.37e+04    1.29e+05\n",
       "Company Type_Subsidiary or Business Segment                7092.4363   4638.752      1.529      0.126   -2001.867    1.62e+04\n",
       "Company Type_Unknown                                       1.333e+04   5272.209      2.528      0.012    2989.785    2.37e+04\n",
       "Company Industry_Accounting                               -7283.7035   8394.986     -0.868      0.386   -2.37e+04    9174.719\n",
       "Company Industry_Advertising & Marketing                   2.651e+04   5342.917      4.962      0.000     1.6e+04     3.7e+04\n",
       "Company Industry_Aerospace & Defense                       2399.8221   9173.686      0.262      0.794   -1.56e+04    2.04e+04\n",
       "Company Industry_Banks & Credit Unions                     6251.9910   6687.258      0.935      0.350   -6858.420    1.94e+04\n",
       "Company Industry_Biotech & Pharmaceuticals                 1521.0290   3763.962      0.404      0.686   -5858.242    8900.300\n",
       "Company Industry_Cable, Internet & Telephone Providers     3.162e+04   4810.530      6.573      0.000    2.22e+04     4.1e+04\n",
       "Company Industry_Colleges & Universities                   7.225e+04   1.61e+04      4.481      0.000    4.06e+04    1.04e+05\n",
       "Company Industry_Commercial Equipment Rental               3.316e+04   6434.124      5.154      0.000    2.05e+04    4.58e+04\n",
       "Company Industry_Computer Hardware & Software              5867.9860   1687.761      3.477      0.001    2559.120    9176.852\n",
       "Company Industry_Consulting                               -3832.8538   4216.804     -0.909      0.363   -1.21e+04    4434.218\n",
       "Company Industry_Consumer Electronics & Appliances Stores  8959.2107   8747.243      1.024      0.306   -8189.816    2.61e+04\n",
       "Company Industry_Consumer Products Manufacturing          -2.946e+04   6906.921     -4.265      0.000    -4.3e+04   -1.59e+04\n",
       "Company Industry_Department, Clothing, & Shoe Stores      -2.488e+04   7772.852     -3.201      0.001   -4.01e+04   -9643.605\n",
       "Company Industry_Education Training Services              -2.718e+04   1.71e+04     -1.588      0.112   -6.07e+04    6380.468\n",
       "Company Industry_Electrical & Electronic Manufacturing     1.275e+04   1.01e+04      1.263      0.207   -7040.274    3.25e+04\n",
       "Company Industry_Energy                                   -1.887e+04   1.07e+04     -1.761      0.078   -3.99e+04    2136.754\n",
       "Company Industry_Enterprise Software & Network Solutions    673.5855   1725.584      0.390      0.696   -2709.433    4056.604\n",
       "Company Industry_Express Delivery Services                -3.414e+04   1.29e+04     -2.655      0.008   -5.93e+04   -8932.054\n",
       "Company Industry_Farm Support Services                      1.38e+04   2764.672      4.990      0.000    8375.912    1.92e+04\n",
       "Company Industry_Federal Agencies                          3.576e+04   1.09e+04      3.267      0.001    1.43e+04    5.72e+04\n",
       "Company Industry_Financial Analytics & Research           -4489.9067   2.23e+04     -0.202      0.840   -4.81e+04    3.91e+04\n",
       "Company Industry_Financial Transaction Processing         -2.646e+04   7087.952     -3.733      0.000   -4.04e+04   -1.26e+04\n",
       "Company Industry_Food & Beverage Manufacturing            -2.539e+04   7731.981     -3.283      0.001   -4.05e+04   -1.02e+04\n",
       "Company Industry_Grocery Stores & Supermarkets            -8.239e+04   1.09e+04     -7.535      0.000   -1.04e+05    -6.1e+04\n",
       "Company Industry_Health Care Services & Hospitals         -6917.0824   2669.365     -2.591      0.010   -1.22e+04   -1683.775\n",
       "Company Industry_Home Centers & Hardware Stores            2.496e+04   1.33e+04      1.880      0.060   -1066.387     5.1e+04\n",
       "Company Industry_Home Furniture & Housewares Stores       -2.254e+04   1.07e+04     -2.112      0.035   -4.35e+04   -1613.862\n",
       "Company Industry_Hotels, Motels, & Resorts                 1.087e-10   3.75e-10      0.290      0.772   -6.27e-10    8.44e-10\n",
       "Company Industry_IT Services                               -1.51e+04   2056.427     -7.341      0.000   -1.91e+04   -1.11e+04\n",
       "Company Industry_Industrial Manufacturing                  8369.6793   2.37e+04      0.353      0.724   -3.81e+04    5.48e+04\n",
       "Company Industry_Insurance Agencies & Brokerages          -2.671e+04   3315.340     -8.058      0.000   -3.32e+04   -2.02e+04\n",
       "Company Industry_Insurance Carriers                        2.583e+04   3131.703      8.246      0.000    1.97e+04     3.2e+04\n",
       "Company Industry_Internet                                  7623.7241   1228.329      6.207      0.000    5215.577       1e+04\n",
       "Company Industry_Investment Banking & Asset Management     1.602e+04   6420.880      2.495      0.013    3432.855    2.86e+04\n",
       "Company Industry_Logistics & Supply Chain                 -5157.1641   1.98e+04     -0.261      0.794   -4.39e+04    3.36e+04\n",
       "Company Industry_Membership Organizations                 -1.941e+04   4190.469     -4.632      0.000   -2.76e+04   -1.12e+04\n",
       "Company Industry_Miscellaneous Manufacturing               5397.1011   2.04e+04      0.264      0.791   -3.46e+04    4.54e+04\n",
       "Company Industry_Motion Picture Production & Distribution   2.07e+04   6873.058      3.011      0.003    7221.971    3.42e+04\n",
       "Company Industry_Municipal Governments                    -1.759e+04   1.66e+04     -1.063      0.288      -5e+04    1.49e+04\n",
       "Company Industry_News Outlet                              -1.561e+04   7811.449     -1.999      0.046   -3.09e+04    -300.153\n",
       "Company Industry_Oil & Gas Services                       -9153.9274   1.84e+04     -0.498      0.618   -4.52e+04    2.69e+04\n",
       "Company Industry_Other Retail Stores                       6.584e+04   1.72e+04      3.823      0.000    3.21e+04    9.96e+04\n",
       "Company Industry_Publishing                                2.023e+04   2.05e+04      0.985      0.325      -2e+04    6.05e+04\n",
       "Company Industry_Real Estate                              -4057.8460   8089.019     -0.502      0.616   -1.99e+04    1.18e+04\n",
       "Company Industry_Research & Development                   -5.502e+04   1.47e+04     -3.738      0.000   -8.39e+04   -2.62e+04\n",
       "Company Industry_Shipping                                  4.893e+04   1.03e+04      4.736      0.000    2.87e+04    6.92e+04\n",
       "Company Industry_Social Assistance                         7260.4811   5047.622      1.438      0.150   -2635.415    1.72e+04\n",
       "Company Industry_Staffing & Outsourcing                    4.598e+04   3290.571     13.973      0.000    3.95e+04    5.24e+04\n",
       "Company Industry_TV Broadcast & Cable Networks            -1.395e+04   1.09e+04     -1.281      0.200   -3.53e+04    7392.151\n",
       "Company Industry_Telecommunications Manufacturing         -2.983e+04   6664.829     -4.476      0.000   -4.29e+04   -1.68e+04\n",
       "Company Industry_Telecommunications Services              -2580.7330   3988.119     -0.647      0.518   -1.04e+04    5237.999\n",
       "Company Industry_Transportation Equipment Manufacturing    1.733e+04   8647.500      2.004      0.045     379.357    3.43e+04\n",
       "Company Industry_Transportation Management                -2.254e+04   2.49e+04     -0.905      0.365   -7.14e+04    2.63e+04\n",
       "Company Industry_Travel Agencies                           9.891e-11   2.64e-10      0.375      0.708   -4.19e-10    6.16e-10\n",
       "Company Industry_Unknown                                   3.833e+04   1.87e+04      2.047      0.041    1615.502     7.5e+04\n",
       "Company Industry_Utilities                                 2.088e+04   1.01e+04      2.062      0.039    1028.230    4.07e+04\n",
       "Company Industry_Vehicle Dealers                          -2.423e+04   1.93e+04     -1.254      0.210   -6.21e+04    1.36e+04\n",
       "Company Industry_Video Games                              -1.024e+04   6148.224     -1.666      0.096   -2.23e+04    1811.789\n",
       "Company Industry_Wholesale                                -2.138e+04   1.16e+04     -1.850      0.064    -4.4e+04    1271.870\n",
       "Company Sector_Accounting & Legal                         -7283.7035   8394.986     -0.868      0.386   -2.37e+04    9174.719\n",
       "Company Sector_Aerospace & Defense                         2399.8221   9173.686      0.262      0.794   -1.56e+04    2.04e+04\n",
       "Company Sector_Agriculture & Forestry                       1.38e+04   2764.672      4.990      0.000    8375.912    1.92e+04\n",
       "Company Sector_Biotech & Pharmaceuticals                   1521.0290   3763.962      0.404      0.686   -5858.242    8900.300\n",
       "Company Sector_Business Services                           6012.5949   2960.300      2.031      0.042     208.908    1.18e+04\n",
       "Company Sector_Education                                   4.508e+04   9992.218      4.511      0.000    2.55e+04    6.47e+04\n",
       "Company Sector_Finance                                    -8672.8445   5381.508     -1.612      0.107   -1.92e+04    1877.636\n",
       "Company Sector_Government                                  1.817e+04   1.25e+04      1.457      0.145   -6282.710    4.26e+04\n",
       "Company Sector_Health Care                                -6917.0824   2669.365     -2.591      0.010   -1.22e+04   -1683.775\n",
       "Company Sector_Information Technology                      -931.5835   2315.693     -0.402      0.687   -5471.513    3608.346\n",
       "Company Sector_Insurance                                   -888.9951   2558.785     -0.347      0.728   -5905.510    4127.519\n",
       "Company Sector_Manufacturing                                -1.1e+04   5643.717     -1.949      0.051   -2.21e+04      66.504\n",
       "Company Sector_Media                                       1119.9539   4921.544      0.228      0.820   -8528.764    1.08e+04\n",
       "Company Sector_Non-Profit                                  7260.4811   5047.622      1.438      0.150   -2635.415    1.72e+04\n",
       "Company Sector_Oil, Gas, Energy & Utilities               -7140.4165   6650.018     -1.074      0.283   -2.02e+04    5896.986\n",
       "Company Sector_Real Estate                                -4057.8460   8089.019     -0.502      0.616   -1.99e+04    1.18e+04\n",
       "Company Sector_Retail                                        1.4e+04   7466.230      1.875      0.061    -640.743    2.86e+04\n",
       "Company Sector_Telecommunications                          -791.2093   3226.489     -0.245      0.806   -7116.762    5534.343\n",
       "Company Sector_Transportation & Logistics                 -1.291e+04   7651.875     -1.687      0.092   -2.79e+04    2093.288\n",
       "Company Sector_Travel & Tourism                             1.37e-12   4.08e-12      0.336      0.737   -6.63e-12    9.37e-12\n",
       "Company Sector_Unknown                                    -2.996e+04   1.79e+04     -1.675      0.094    -6.5e+04    5095.455\n",
       "Company Revenue_$1 to $2 billion (USD)                     -1.87e+04   4928.056     -3.794      0.000   -2.84e+04   -9036.628\n",
       "Company Revenue_$1 to $5 million (USD)                    -2.919e+04   3242.209     -9.004      0.000   -3.56e+04   -2.28e+04\n",
       "Company Revenue_$10 to $25 million (USD)                   5565.0195   3577.117      1.556      0.120   -1447.942    1.26e+04\n",
       "Company Revenue_$10+ billion (USD)                         7023.1056   2816.680      2.493      0.013    1500.987    1.25e+04\n",
       "Company Revenue_$100 to $500 million (USD)                -2.453e+04   2443.612    -10.040      0.000   -2.93e+04   -1.97e+04\n",
       "Company Revenue_$2 to $5 billion (USD)                      2.83e+04   2325.575     12.168      0.000    2.37e+04    3.29e+04\n",
       "Company Revenue_$25 to $50 million (USD)                   8981.6019   2278.179      3.942      0.000    4515.217    1.34e+04\n",
       "Company Revenue_$5 to $10 billion (USD)                    4264.1362   3045.118      1.400      0.161   -1705.837    1.02e+04\n",
       "Company Revenue_$5 to $10 million (USD)                   -6438.4195   3999.080     -1.610      0.107   -1.43e+04    1401.801\n",
       "Company Revenue_$50 to $100 million (USD)                 -1.459e+04   4033.859     -3.616      0.000   -2.25e+04   -6676.730\n",
       "Company Revenue_$500 million to $1 billion (USD)           1.922e+04   5005.168      3.841      0.000    9411.333     2.9e+04\n",
       "Company Revenue_Less than $1 million (USD)                 1.082e+04   3118.254      3.469      0.001    4705.248    1.69e+04\n",
       "Company Revenue_Unknown                                    2.525e+04   5005.555      5.045      0.000    1.54e+04    3.51e+04\n",
       "Company Revenue_Unknown / Non-Applicable                   2829.1431   1297.223      2.181      0.029     285.929    5372.357\n",
       "Level_Intern                                              -5.917e+04   1.57e+04     -3.758      0.000      -9e+04   -2.83e+04\n",
       "Level_Junior                                               1.409e+04   4706.853      2.994      0.003    4863.724    2.33e+04\n",
       "Level_Normal                                               2.491e+04   4317.336      5.771      0.000    1.64e+04    3.34e+04\n",
       "Level_Senior                                               3.897e+04   4364.057      8.930      0.000    3.04e+04    4.75e+04\n",
       "Currency_CA                                                3985.2473   2822.265      1.412      0.158   -1547.821    9518.316\n",
       "Currency_USD                                               1.482e+04   3295.313      4.498      0.000    8361.417    2.13e+04\n",
       "Role_Artificial Intelligence                              -1.074e+04   4150.397     -2.588      0.010   -1.89e+04   -2605.920\n",
       "Role_BackEnd                                                1.13e+04   2574.950      4.387      0.000    6247.433    1.63e+04\n",
       "Role_Data Analyst                                         -1.719e+04   1443.672    -11.910      0.000      -2e+04   -1.44e+04\n",
       "Role_Data Engineer                                        -1.002e+04   2101.829     -4.766      0.000   -1.41e+04   -5895.875\n",
       "Role_Data Researcher                                        1.07e+04   2794.934      3.828      0.000    5219.823    1.62e+04\n",
       "Role_Data SWE                                              -754.3193   3931.444     -0.192      0.848   -8461.940    6953.301\n",
       "Role_Data Science                                          -178.6542   1324.462     -0.135      0.893   -2775.270    2417.962\n",
       "Role_FrontEnd                                              8378.3593   2647.595      3.165      0.002    3187.732    1.36e+04\n",
       "Role_Full Stack                                            1.279e+04   1462.183      8.750      0.000    9927.444    1.57e+04\n",
       "Role_General Data                                          3032.8051   5146.556      0.589      0.556   -7057.052    1.31e+04\n",
       "Role_Infra/System SWE                                      5952.0690   2975.286      2.001      0.046     119.002    1.18e+04\n",
       "Role_Machine Learning                                      6877.8753   1678.679      4.097      0.000    3586.814    1.02e+04\n",
       "Role_SWE                                                    1.42e+04   1159.031     12.250      0.000    1.19e+04    1.65e+04\n",
       "Role_Test                                                 -1.553e+04   5609.815     -2.769      0.006   -2.65e+04   -4536.586\n",
       "==============================================================================\n",
       "Omnibus:                      220.265   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              582.149\n",
       "Skew:                           0.250   Prob(JB):                    3.87e-127\n",
       "Kurtosis:                       4.684   Cond. No.                     1.92e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.52e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# first model is multiple linear regression\n",
    "def multiple_linear_regression(X_train, y_train):\n",
    "    X_sm = X_train = sm.add_constant(X_train)\n",
    "    model = sm.OLS(y_train, X_train)\n",
    "    return model.fit()\n",
    "sm_min_model = multiple_linear_regression(X_train, y_train['Minimum'])\n",
    "sm_max_model = multiple_linear_regression(X_train, y_train['Maximum'])\n",
    "sm_min_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "60a8378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_cross_val:  -16748.748958012675\n",
      "max_cross_val:  -18552.570887599293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lm_min = lm_max = LinearRegression()\n",
    "lm_min.fit(X_train, y_train['Minimum'])\n",
    "lm_max.fit(X_train, y_train['Maximum'])\n",
    "\n",
    "print(\"min_cross_val:\", np.mean(cross_val_score(lm_min,X_train,y_train['Minimum'], scoring = 'neg_mean_absolute_error', cv= 3)))\n",
    "print(\"max_cross_val:\", np.mean(cross_val_score(lm_min,X_train,y_train['Maximum'], scoring = 'neg_mean_absolute_error', cv= 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8913562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE minimum: 50148.06718202257\n",
      "MAE maximum: 17568.945014277666\n"
     ]
    }
   ],
   "source": [
    "lm_min_predict = lm_min.predict(X_test)\n",
    "lm_max_predict = lm_min.predict(X_test)\n",
    "\n",
    "print(\"MAE minimum:\", mean_absolute_error(y_test['Minimum'],tpred_lm_min))\n",
    "print(\"MAE maximum:\", mean_absolute_error(y_test['Maximum'],tpred_lm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b4b97e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 128)               23680     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 123,010\n",
      "Trainable params: 123,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Deep learning model\n",
    "dl_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, input_dim = X_train.shape[1], activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='linear')\n",
    "])\n",
    "\n",
    "dl_model.compile(optimizer='adam',\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['accuracy'])\n",
    "dl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2d9583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "114/114 [==============================] - 1s 3ms/step - loss: 78192.4062 - accuracy: 0.8727 - val_loss: 51003.0156 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 51003.01562, saving model to Weights-001--51003.01562.hdf5\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49904.0820 - accuracy: 0.8962 - val_loss: 49678.5000 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00002: val_loss improved from 51003.01562 to 49678.50000, saving model to Weights-002--49678.50000.hdf5\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48363.2656 - accuracy: 0.8962 - val_loss: 47560.9219 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00003: val_loss improved from 49678.50000 to 47560.92188, saving model to Weights-003--47560.92188.hdf5\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46049.7070 - accuracy: 0.8962 - val_loss: 45134.5078 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00004: val_loss improved from 47560.92188 to 45134.50781, saving model to Weights-004--45134.50781.hdf5\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39479.8672 - accuracy: 0.8962 - val_loss: 33954.7734 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00005: val_loss improved from 45134.50781 to 33954.77344, saving model to Weights-005--33954.77344.hdf5\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33679.8867 - accuracy: 0.8962 - val_loss: 32558.2988 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00006: val_loss improved from 33954.77344 to 32558.29883, saving model to Weights-006--32558.29883.hdf5\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32830.6758 - accuracy: 0.8962 - val_loss: 31673.1113 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00007: val_loss improved from 32558.29883 to 31673.11133, saving model to Weights-007--31673.11133.hdf5\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 32553.8574 - accuracy: 0.8962 - val_loss: 31022.8945 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00008: val_loss improved from 31673.11133 to 31022.89453, saving model to Weights-008--31022.89453.hdf5\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31435.6016 - accuracy: 0.8962 - val_loss: 30662.3359 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00009: val_loss improved from 31022.89453 to 30662.33594, saving model to Weights-009--30662.33594.hdf5\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30794.5391 - accuracy: 0.8962 - val_loss: 29799.9629 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00010: val_loss improved from 30662.33594 to 29799.96289, saving model to Weights-010--29799.96289.hdf5\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30200.0293 - accuracy: 0.8948 - val_loss: 29194.4863 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00011: val_loss improved from 29799.96289 to 29194.48633, saving model to Weights-011--29194.48633.hdf5\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29185.9121 - accuracy: 0.8962 - val_loss: 28253.2930 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00012: val_loss improved from 29194.48633 to 28253.29297, saving model to Weights-012--28253.29297.hdf5\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28182.1758 - accuracy: 0.8962 - val_loss: 26590.4902 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00013: val_loss improved from 28253.29297 to 26590.49023, saving model to Weights-013--26590.49023.hdf5\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26827.2031 - accuracy: 0.8962 - val_loss: 27257.9375 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 26590.49023\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26697.1445 - accuracy: 0.8962 - val_loss: 24475.3691 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00015: val_loss improved from 26590.49023 to 24475.36914, saving model to Weights-015--24475.36914.hdf5\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25080.3164 - accuracy: 0.8962 - val_loss: 24159.7227 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00016: val_loss improved from 24475.36914 to 24159.72266, saving model to Weights-016--24159.72266.hdf5\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23978.2520 - accuracy: 0.8962 - val_loss: 23804.2754 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00017: val_loss improved from 24159.72266 to 23804.27539, saving model to Weights-017--23804.27539.hdf5\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24027.8477 - accuracy: 0.8959 - val_loss: 22858.3223 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00018: val_loss improved from 23804.27539 to 22858.32227, saving model to Weights-018--22858.32227.hdf5\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23362.3105 - accuracy: 0.8962 - val_loss: 23007.2402 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 22858.32227\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23407.4062 - accuracy: 0.8962 - val_loss: 23250.4023 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 22858.32227\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22890.7227 - accuracy: 0.8962 - val_loss: 22254.4629 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00021: val_loss improved from 22858.32227 to 22254.46289, saving model to Weights-021--22254.46289.hdf5\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22632.8438 - accuracy: 0.8962 - val_loss: 22045.3945 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00022: val_loss improved from 22254.46289 to 22045.39453, saving model to Weights-022--22045.39453.hdf5\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22389.8574 - accuracy: 0.8962 - val_loss: 22675.9512 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 22045.39453\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22308.3691 - accuracy: 0.8962 - val_loss: 22108.1543 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 22045.39453\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22555.1211 - accuracy: 0.8962 - val_loss: 21726.6289 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00025: val_loss improved from 22045.39453 to 21726.62891, saving model to Weights-025--21726.62891.hdf5\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22294.9805 - accuracy: 0.8962 - val_loss: 21517.5801 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00026: val_loss improved from 21726.62891 to 21517.58008, saving model to Weights-026--21517.58008.hdf5\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21992.5508 - accuracy: 0.8962 - val_loss: 23048.8008 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 21517.58008\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21972.9785 - accuracy: 0.8962 - val_loss: 21625.2422 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 21517.58008\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21827.3945 - accuracy: 0.8962 - val_loss: 21137.8965 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00029: val_loss improved from 21517.58008 to 21137.89648, saving model to Weights-029--21137.89648.hdf5\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21364.7246 - accuracy: 0.8962 - val_loss: 22130.4004 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 21137.89648\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21259.2422 - accuracy: 0.8962 - val_loss: 21585.0977 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 21137.89648\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21475.4297 - accuracy: 0.8956 - val_loss: 21059.6719 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00032: val_loss improved from 21137.89648 to 21059.67188, saving model to Weights-032--21059.67188.hdf5\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21054.1504 - accuracy: 0.8962 - val_loss: 21101.6328 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 21059.67188\n",
      "Epoch 34/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 21478.2441 - accuracy: 0.8962 - val_loss: 20976.1348 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00034: val_loss improved from 21059.67188 to 20976.13477, saving model to Weights-034--20976.13477.hdf5\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21663.5371 - accuracy: 0.8962 - val_loss: 24291.2676 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 20976.13477\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20970.8008 - accuracy: 0.8962 - val_loss: 21046.3262 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 20976.13477\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20677.0098 - accuracy: 0.8962 - val_loss: 20608.5664 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00037: val_loss improved from 20976.13477 to 20608.56641, saving model to Weights-037--20608.56641.hdf5\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20569.7695 - accuracy: 0.8962 - val_loss: 20676.3125 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 20608.56641\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20345.6309 - accuracy: 0.8962 - val_loss: 20197.1387 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00039: val_loss improved from 20608.56641 to 20197.13867, saving model to Weights-039--20197.13867.hdf5\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21283.5977 - accuracy: 0.8962 - val_loss: 21621.0059 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 20197.13867\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20518.0312 - accuracy: 0.8962 - val_loss: 20306.7676 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 20197.13867\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20759.4629 - accuracy: 0.8962 - val_loss: 20266.5723 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 20197.13867\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20294.7246 - accuracy: 0.8962 - val_loss: 20072.4336 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00043: val_loss improved from 20197.13867 to 20072.43359, saving model to Weights-043--20072.43359.hdf5\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19905.0898 - accuracy: 0.8962 - val_loss: 20066.0488 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00044: val_loss improved from 20072.43359 to 20066.04883, saving model to Weights-044--20066.04883.hdf5\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20266.3418 - accuracy: 0.8962 - val_loss: 19788.1543 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00045: val_loss improved from 20066.04883 to 19788.15430, saving model to Weights-045--19788.15430.hdf5\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20003.4551 - accuracy: 0.8962 - val_loss: 20224.1406 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 19788.15430\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20039.1465 - accuracy: 0.8962 - val_loss: 19928.1426 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 19788.15430\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19752.0215 - accuracy: 0.8962 - val_loss: 19993.8789 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 19788.15430\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19646.9609 - accuracy: 0.8962 - val_loss: 20006.4805 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 19788.15430\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19460.1367 - accuracy: 0.8962 - val_loss: 20241.1914 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 19788.15430\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19474.0977 - accuracy: 0.8962 - val_loss: 19214.0410 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00051: val_loss improved from 19788.15430 to 19214.04102, saving model to Weights-051--19214.04102.hdf5\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19390.4375 - accuracy: 0.8962 - val_loss: 19843.1016 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 19214.04102\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19307.2734 - accuracy: 0.8962 - val_loss: 19974.0059 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 19214.04102\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19212.2832 - accuracy: 0.8962 - val_loss: 18990.4961 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00054: val_loss improved from 19214.04102 to 18990.49609, saving model to Weights-054--18990.49609.hdf5\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19167.8008 - accuracy: 0.8962 - val_loss: 19046.0391 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 18990.49609\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18849.5586 - accuracy: 0.8962 - val_loss: 18782.5312 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00056: val_loss improved from 18990.49609 to 18782.53125, saving model to Weights-056--18782.53125.hdf5\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18940.3984 - accuracy: 0.8962 - val_loss: 18930.7598 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 18782.53125\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18804.8047 - accuracy: 0.8962 - val_loss: 18891.5547 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 18782.53125\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18760.4824 - accuracy: 0.8962 - val_loss: 19099.9902 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 18782.53125\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18645.3555 - accuracy: 0.8962 - val_loss: 18727.1074 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00060: val_loss improved from 18782.53125 to 18727.10742, saving model to Weights-060--18727.10742.hdf5\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18809.4688 - accuracy: 0.8962 - val_loss: 19299.7266 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 18727.10742\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18654.4922 - accuracy: 0.8962 - val_loss: 18433.5996 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00062: val_loss improved from 18727.10742 to 18433.59961, saving model to Weights-062--18433.59961.hdf5\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18371.0332 - accuracy: 0.8962 - val_loss: 19189.1914 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 18433.59961\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18008.5215 - accuracy: 0.8962 - val_loss: 18125.0547 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00064: val_loss improved from 18433.59961 to 18125.05469, saving model to Weights-064--18125.05469.hdf5\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17889.2012 - accuracy: 0.8962 - val_loss: 17887.7520 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00065: val_loss improved from 18125.05469 to 17887.75195, saving model to Weights-065--17887.75195.hdf5\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18533.8047 - accuracy: 0.8962 - val_loss: 18219.6523 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 17887.75195\n",
      "Epoch 67/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17695.3184 - accuracy: 0.8962 - val_loss: 17799.0020 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00067: val_loss improved from 17887.75195 to 17799.00195, saving model to Weights-067--17799.00195.hdf5\n",
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17897.7500 - accuracy: 0.8962 - val_loss: 18444.9375 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 17799.00195\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17796.8926 - accuracy: 0.8962 - val_loss: 18752.9434 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 17799.00195\n",
      "Epoch 70/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 17950.8711 - accuracy: 0.8962 - val_loss: 18205.0371 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 17799.00195\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17552.5469 - accuracy: 0.8962 - val_loss: 18546.2773 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 17799.00195\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17146.1797 - accuracy: 0.8962 - val_loss: 17794.8672 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00072: val_loss improved from 17799.00195 to 17794.86719, saving model to Weights-072--17794.86719.hdf5\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17095.8008 - accuracy: 0.8962 - val_loss: 17206.3594 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00073: val_loss improved from 17794.86719 to 17206.35938, saving model to Weights-073--17206.35938.hdf5\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17074.7363 - accuracy: 0.8962 - val_loss: 17118.5684 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00074: val_loss improved from 17206.35938 to 17118.56836, saving model to Weights-074--17118.56836.hdf5\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17142.5039 - accuracy: 0.8962 - val_loss: 16907.2227 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00075: val_loss improved from 17118.56836 to 16907.22266, saving model to Weights-075--16907.22266.hdf5\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16899.2383 - accuracy: 0.8962 - val_loss: 18065.7715 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 16907.22266\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16956.1953 - accuracy: 0.8962 - val_loss: 16659.2559 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00077: val_loss improved from 16907.22266 to 16659.25586, saving model to Weights-077--16659.25586.hdf5\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16701.2012 - accuracy: 0.8962 - val_loss: 17526.8066 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 16659.25586\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16274.2988 - accuracy: 0.8962 - val_loss: 16990.3633 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 16659.25586\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16707.6738 - accuracy: 0.8962 - val_loss: 17073.4902 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 16659.25586\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16596.7129 - accuracy: 0.8962 - val_loss: 16738.0566 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 16659.25586\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16131.0361 - accuracy: 0.8970 - val_loss: 17606.0859 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 16659.25586\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16398.2207 - accuracy: 0.8981 - val_loss: 17167.8750 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 16659.25586\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16153.4941 - accuracy: 0.8976 - val_loss: 15840.7861 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00084: val_loss improved from 16659.25586 to 15840.78613, saving model to Weights-084--15840.78613.hdf5\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15980.1152 - accuracy: 0.8978 - val_loss: 16645.2070 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 15840.78613\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16073.5391 - accuracy: 0.8965 - val_loss: 16050.0205 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 15840.78613\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16561.3438 - accuracy: 0.8959 - val_loss: 15828.4209 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00087: val_loss improved from 15840.78613 to 15828.42090, saving model to Weights-087--15828.42090.hdf5\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15472.6377 - accuracy: 0.8962 - val_loss: 17171.4434 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 15828.42090\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15739.2051 - accuracy: 0.8973 - val_loss: 15855.5762 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 15828.42090\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15370.1787 - accuracy: 0.8962 - val_loss: 16482.1758 - val_accuracy: 0.8874\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 15828.42090\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15498.5557 - accuracy: 0.8937 - val_loss: 15706.9561 - val_accuracy: 0.8907\n",
      "\n",
      "Epoch 00091: val_loss improved from 15828.42090 to 15706.95605, saving model to Weights-091--15706.95605.hdf5\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15755.6006 - accuracy: 0.8945 - val_loss: 16476.7793 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 15706.95605\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15545.3701 - accuracy: 0.8934 - val_loss: 17071.5273 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 15706.95605\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15369.1924 - accuracy: 0.8948 - val_loss: 15351.9688 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00094: val_loss improved from 15706.95605 to 15351.96875, saving model to Weights-094--15351.96875.hdf5\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15167.1904 - accuracy: 0.8965 - val_loss: 16414.8633 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 15351.96875\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15797.9209 - accuracy: 0.8937 - val_loss: 15123.3018 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00096: val_loss improved from 15351.96875 to 15123.30176, saving model to Weights-096--15123.30176.hdf5\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15266.9541 - accuracy: 0.8932 - val_loss: 15830.3643 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 15123.30176\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15138.9521 - accuracy: 0.8940 - val_loss: 15108.3379 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00098: val_loss improved from 15123.30176 to 15108.33789, saving model to Weights-098--15108.33789.hdf5\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15120.8018 - accuracy: 0.8945 - val_loss: 14887.8115 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00099: val_loss improved from 15108.33789 to 14887.81152, saving model to Weights-099--14887.81152.hdf5\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14953.6602 - accuracy: 0.8934 - val_loss: 14778.0498 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00100: val_loss improved from 14887.81152 to 14778.04980, saving model to Weights-100--14778.04980.hdf5\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15521.3916 - accuracy: 0.8940 - val_loss: 14997.8379 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 14778.04980\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14913.9541 - accuracy: 0.8937 - val_loss: 14562.3271 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00102: val_loss improved from 14778.04980 to 14562.32715, saving model to Weights-102--14562.32715.hdf5\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14825.3652 - accuracy: 0.8948 - val_loss: 15278.1475 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 14562.32715\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14479.8408 - accuracy: 0.8948 - val_loss: 15395.3418 - val_accuracy: 0.8885\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 14562.32715\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14847.7803 - accuracy: 0.8898 - val_loss: 14835.7627 - val_accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00105: val_loss did not improve from 14562.32715\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14476.3369 - accuracy: 0.8920 - val_loss: 14937.1543 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 14562.32715\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14614.6396 - accuracy: 0.8932 - val_loss: 15581.7559 - val_accuracy: 0.8918\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 14562.32715\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14711.6387 - accuracy: 0.8951 - val_loss: 14397.9668 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00108: val_loss improved from 14562.32715 to 14397.96680, saving model to Weights-108--14397.96680.hdf5\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14620.1885 - accuracy: 0.8915 - val_loss: 15453.4551 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 14397.96680\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14370.6260 - accuracy: 0.8926 - val_loss: 14442.1807 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 14397.96680\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14137.3584 - accuracy: 0.8945 - val_loss: 14375.8418 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00111: val_loss improved from 14397.96680 to 14375.84180, saving model to Weights-111--14375.84180.hdf5\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14160.5645 - accuracy: 0.8937 - val_loss: 14421.0400 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 14375.84180\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14347.0811 - accuracy: 0.8940 - val_loss: 15719.3740 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 14375.84180\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14246.6074 - accuracy: 0.8948 - val_loss: 15071.5488 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 14375.84180\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14434.8516 - accuracy: 0.8967 - val_loss: 14711.9580 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 14375.84180\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14071.2412 - accuracy: 0.8948 - val_loss: 14934.8193 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 14375.84180\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14067.0020 - accuracy: 0.8937 - val_loss: 14266.2568 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00117: val_loss improved from 14375.84180 to 14266.25684, saving model to Weights-117--14266.25684.hdf5\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14248.4883 - accuracy: 0.8995 - val_loss: 15009.7490 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 14266.25684\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14466.9102 - accuracy: 0.8984 - val_loss: 14349.8311 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 14266.25684\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14232.2891 - accuracy: 0.8965 - val_loss: 14178.8047 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00120: val_loss improved from 14266.25684 to 14178.80469, saving model to Weights-120--14178.80469.hdf5\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13840.7939 - accuracy: 0.8965 - val_loss: 14073.3877 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00121: val_loss improved from 14178.80469 to 14073.38770, saving model to Weights-121--14073.38770.hdf5\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13868.3955 - accuracy: 0.8951 - val_loss: 13944.9932 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00122: val_loss improved from 14073.38770 to 13944.99316, saving model to Weights-122--13944.99316.hdf5\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13756.4863 - accuracy: 0.8954 - val_loss: 14058.6943 - val_accuracy: 0.8962\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 13944.99316\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13933.2656 - accuracy: 0.8943 - val_loss: 13663.4941 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00124: val_loss improved from 13944.99316 to 13663.49414, saving model to Weights-124--13663.49414.hdf5\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13843.3447 - accuracy: 0.8981 - val_loss: 15334.5225 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 13663.49414\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13742.5166 - accuracy: 0.8965 - val_loss: 14031.6523 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 13663.49414\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13558.2080 - accuracy: 0.8965 - val_loss: 13804.6455 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 13663.49414\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14140.2646 - accuracy: 0.9001 - val_loss: 15400.6533 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 13663.49414\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13743.8926 - accuracy: 0.8995 - val_loss: 13917.9062 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 13663.49414\n",
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13470.8047 - accuracy: 0.8978 - val_loss: 14106.4795 - val_accuracy: 0.8974\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 13663.49414\n",
      "Epoch 131/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13426.3096 - accuracy: 0.9017 - val_loss: 14021.6934 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 13663.49414\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13689.5781 - accuracy: 0.8973 - val_loss: 15251.6855 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 13663.49414\n",
      "Epoch 133/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13910.8799 - accuracy: 0.8973 - val_loss: 13288.0459 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00133: val_loss improved from 13663.49414 to 13288.04590, saving model to Weights-133--13288.04590.hdf5\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13508.8955 - accuracy: 0.9001 - val_loss: 13484.0508 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 13288.04590\n",
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13278.2275 - accuracy: 0.8976 - val_loss: 14171.0283 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 13288.04590\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13517.4619 - accuracy: 0.8998 - val_loss: 13131.1943 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00136: val_loss improved from 13288.04590 to 13131.19434, saving model to Weights-136--13131.19434.hdf5\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13306.5205 - accuracy: 0.9006 - val_loss: 14383.5967 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 13131.19434\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13260.0088 - accuracy: 0.8995 - val_loss: 13947.1846 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 13131.19434\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13214.5410 - accuracy: 0.8976 - val_loss: 13649.3594 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 13131.19434\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13442.1660 - accuracy: 0.8998 - val_loss: 13290.1533 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 13131.19434\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13063.5449 - accuracy: 0.8984 - val_loss: 13674.7998 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 13131.19434\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13288.8242 - accuracy: 0.8984 - val_loss: 13783.2559 - val_accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00142: val_loss did not improve from 13131.19434\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13268.9297 - accuracy: 0.9006 - val_loss: 14068.0352 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 13131.19434\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13319.1367 - accuracy: 0.8992 - val_loss: 13376.1387 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 13131.19434\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13039.6699 - accuracy: 0.9001 - val_loss: 13539.0713 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 13131.19434\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13209.2354 - accuracy: 0.8998 - val_loss: 13532.8447 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 13131.19434\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13306.6768 - accuracy: 0.8995 - val_loss: 13183.8613 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 13131.19434\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13270.4746 - accuracy: 0.9009 - val_loss: 12936.7832 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00148: val_loss improved from 13131.19434 to 12936.78320, saving model to Weights-148--12936.78320.hdf5\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12882.5010 - accuracy: 0.8973 - val_loss: 13445.2656 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 12936.78320\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13084.5205 - accuracy: 0.8987 - val_loss: 13494.6553 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 12936.78320\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13030.6973 - accuracy: 0.8990 - val_loss: 13260.2051 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 12936.78320\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12785.1729 - accuracy: 0.9001 - val_loss: 14141.0303 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 12936.78320\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13175.9795 - accuracy: 0.8984 - val_loss: 12677.5781 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00153: val_loss improved from 12936.78320 to 12677.57812, saving model to Weights-153--12677.57812.hdf5\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12624.5703 - accuracy: 0.8992 - val_loss: 13119.5869 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 12677.57812\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12753.5928 - accuracy: 0.9003 - val_loss: 13597.3896 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 12677.57812\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12612.6641 - accuracy: 0.8995 - val_loss: 12764.9951 - val_accuracy: 0.8918\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 12677.57812\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12585.5752 - accuracy: 0.8998 - val_loss: 13364.5576 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 12677.57812\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12714.9941 - accuracy: 0.9028 - val_loss: 12838.9092 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 12677.57812\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12956.9033 - accuracy: 0.9034 - val_loss: 14070.7646 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 12677.57812\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13114.1318 - accuracy: 0.9001 - val_loss: 13375.1104 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 12677.57812\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13144.0537 - accuracy: 0.8992 - val_loss: 12936.0430 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 12677.57812\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12759.7910 - accuracy: 0.8995 - val_loss: 12706.2070 - val_accuracy: 0.8962\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 12677.57812\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12585.5000 - accuracy: 0.9006 - val_loss: 14984.6641 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 12677.57812\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12952.1924 - accuracy: 0.8981 - val_loss: 12362.9629 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00164: val_loss improved from 12677.57812 to 12362.96289, saving model to Weights-164--12362.96289.hdf5\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12256.9219 - accuracy: 0.8973 - val_loss: 12757.6660 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 12362.96289\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12210.0029 - accuracy: 0.9014 - val_loss: 12425.1885 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 12362.96289\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12471.9580 - accuracy: 0.9006 - val_loss: 12770.1689 - val_accuracy: 0.8962\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 12362.96289\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12724.4316 - accuracy: 0.8978 - val_loss: 12245.0947 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00168: val_loss improved from 12362.96289 to 12245.09473, saving model to Weights-168--12245.09473.hdf5\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12305.2715 - accuracy: 0.8998 - val_loss: 12810.0762 - val_accuracy: 0.8962\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 12245.09473\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12328.7705 - accuracy: 0.8990 - val_loss: 12749.5010 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 12245.09473\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12760.3848 - accuracy: 0.9003 - val_loss: 12775.7812 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 12245.09473\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12648.1924 - accuracy: 0.9009 - val_loss: 13869.2324 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 12245.09473\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12512.8457 - accuracy: 0.9017 - val_loss: 12324.8496 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 12245.09473\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12460.2246 - accuracy: 0.9012 - val_loss: 13754.8506 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 12245.09473\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12218.2695 - accuracy: 0.8976 - val_loss: 12557.7832 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 12245.09473\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11984.8740 - accuracy: 0.8998 - val_loss: 12432.7490 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 12245.09473\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12312.2773 - accuracy: 0.9053 - val_loss: 13765.7295 - val_accuracy: 0.8974\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 12245.09473\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12122.7822 - accuracy: 0.8998 - val_loss: 12413.3633 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 12245.09473\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12009.4199 - accuracy: 0.9020 - val_loss: 12684.7471 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 12245.09473\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11993.0615 - accuracy: 0.9064 - val_loss: 12680.9346 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 12245.09473\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 11809.2168 - accuracy: 0.8995 - val_loss: 13043.6621 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 12245.09473\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12339.7783 - accuracy: 0.8992 - val_loss: 13070.8486 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 12245.09473\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 11999.9023 - accuracy: 0.9045 - val_loss: 12571.7227 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 12245.09473\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12320.7070 - accuracy: 0.9064 - val_loss: 13208.0479 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 12245.09473\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12120.5400 - accuracy: 0.9023 - val_loss: 12255.5107 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 12245.09473\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12340.7197 - accuracy: 0.9003 - val_loss: 13436.0273 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 12245.09473\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12018.8613 - accuracy: 0.9036 - val_loss: 12240.8086 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00187: val_loss improved from 12245.09473 to 12240.80859, saving model to Weights-187--12240.80859.hdf5\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 11746.7627 - accuracy: 0.8981 - val_loss: 12175.2324 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00188: val_loss improved from 12240.80859 to 12175.23242, saving model to Weights-188--12175.23242.hdf5\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11750.9141 - accuracy: 0.9039 - val_loss: 12080.8525 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00189: val_loss improved from 12175.23242 to 12080.85254, saving model to Weights-189--12080.85254.hdf5\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11800.1914 - accuracy: 0.9036 - val_loss: 11934.8301 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00190: val_loss improved from 12080.85254 to 11934.83008, saving model to Weights-190--11934.83008.hdf5\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11942.3545 - accuracy: 0.9028 - val_loss: 11955.5117 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 11934.83008\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11661.7031 - accuracy: 0.9001 - val_loss: 12948.0732 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 11934.83008\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12348.6992 - accuracy: 0.9017 - val_loss: 15687.7939 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 11934.83008\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11758.9697 - accuracy: 0.9009 - val_loss: 11970.6240 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 11934.83008\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11810.2764 - accuracy: 0.8990 - val_loss: 11727.9004 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00195: val_loss improved from 11934.83008 to 11727.90039, saving model to Weights-195--11727.90039.hdf5\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11812.1523 - accuracy: 0.9017 - val_loss: 12746.3291 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 11727.90039\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11823.2168 - accuracy: 0.9034 - val_loss: 12797.8994 - val_accuracy: 0.8974\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 11727.90039\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11796.3594 - accuracy: 0.9028 - val_loss: 12057.1875 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 11727.90039\n",
      "Epoch 199/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11538.1602 - accuracy: 0.9031 - val_loss: 13278.2568 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 11727.90039\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12131.0820 - accuracy: 0.9047 - val_loss: 12184.0938 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 11727.90039\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11935.0938 - accuracy: 0.9050 - val_loss: 11984.1006 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 11727.90039\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11673.6455 - accuracy: 0.9036 - val_loss: 12297.2793 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 11727.90039\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11507.6084 - accuracy: 0.9045 - val_loss: 12193.7783 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 11727.90039\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11479.3408 - accuracy: 0.9039 - val_loss: 11592.0273 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00204: val_loss improved from 11727.90039 to 11592.02734, saving model to Weights-204--11592.02734.hdf5\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11569.5420 - accuracy: 0.9020 - val_loss: 12791.3887 - val_accuracy: 0.8985\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 11592.02734\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11322.5303 - accuracy: 0.9039 - val_loss: 11742.7764 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 11592.02734\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11561.9268 - accuracy: 0.9053 - val_loss: 12056.4609 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 11592.02734\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11403.0918 - accuracy: 0.9047 - val_loss: 12960.0693 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 11592.02734\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11464.8135 - accuracy: 0.9025 - val_loss: 13252.2891 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 11592.02734\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11761.1201 - accuracy: 0.9034 - val_loss: 12587.2100 - val_accuracy: 0.9040\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 11592.02734\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11762.2041 - accuracy: 0.9053 - val_loss: 12325.3906 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 11592.02734\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11492.4824 - accuracy: 0.9061 - val_loss: 11449.0498 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00212: val_loss improved from 11592.02734 to 11449.04980, saving model to Weights-212--11449.04980.hdf5\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11594.8076 - accuracy: 0.9053 - val_loss: 12116.0654 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 11449.04980\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11867.0049 - accuracy: 0.9047 - val_loss: 11787.8057 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 11449.04980\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11016.6338 - accuracy: 0.9031 - val_loss: 12378.4492 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 11449.04980\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11733.2910 - accuracy: 0.9039 - val_loss: 12306.5322 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 11449.04980\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10994.1357 - accuracy: 0.9012 - val_loss: 12427.9004 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 11449.04980\n",
      "Epoch 218/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 11209.3945 - accuracy: 0.9039 - val_loss: 11611.5322 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 11449.04980\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10856.7021 - accuracy: 0.9053 - val_loss: 11353.3018 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00219: val_loss improved from 11449.04980 to 11353.30176, saving model to Weights-219--11353.30176.hdf5\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11183.0977 - accuracy: 0.9050 - val_loss: 12055.9912 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 11353.30176\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11420.9531 - accuracy: 0.9072 - val_loss: 11192.2051 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00221: val_loss improved from 11353.30176 to 11192.20508, saving model to Weights-221--11192.20508.hdf5\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10925.8262 - accuracy: 0.9092 - val_loss: 12079.8965 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 11192.20508\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11223.7080 - accuracy: 0.9067 - val_loss: 11270.4082 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 11192.20508\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10788.1260 - accuracy: 0.9064 - val_loss: 11364.9697 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 11192.20508\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10982.2559 - accuracy: 0.9070 - val_loss: 13252.1602 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 11192.20508\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11175.7236 - accuracy: 0.9039 - val_loss: 11900.9609 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 11192.20508\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11053.8867 - accuracy: 0.9045 - val_loss: 12142.8936 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 11192.20508\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11775.4336 - accuracy: 0.9053 - val_loss: 11827.3535 - val_accuracy: 0.8985\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 11192.20508\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11100.6514 - accuracy: 0.9042 - val_loss: 11318.6719 - val_accuracy: 0.8985\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 11192.20508\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11162.1631 - accuracy: 0.9083 - val_loss: 11800.3330 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 11192.20508\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11282.7041 - accuracy: 0.9067 - val_loss: 11862.8662 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 11192.20508\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10888.6016 - accuracy: 0.9097 - val_loss: 12760.6729 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 11192.20508\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11246.8721 - accuracy: 0.9067 - val_loss: 10922.2705 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00233: val_loss improved from 11192.20508 to 10922.27051, saving model to Weights-233--10922.27051.hdf5\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10865.0957 - accuracy: 0.9059 - val_loss: 11072.2578 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 10922.27051\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11296.7168 - accuracy: 0.9064 - val_loss: 10858.9893 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00235: val_loss improved from 10922.27051 to 10858.98926, saving model to Weights-235--10858.98926.hdf5\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10867.5391 - accuracy: 0.9045 - val_loss: 11173.1885 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 10858.98926\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10957.4004 - accuracy: 0.9072 - val_loss: 11623.9922 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 10858.98926\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11435.6484 - accuracy: 0.9075 - val_loss: 11977.9844 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 10858.98926\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11071.5420 - accuracy: 0.9047 - val_loss: 10842.4609 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00239: val_loss improved from 10858.98926 to 10842.46094, saving model to Weights-239--10842.46094.hdf5\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10876.8291 - accuracy: 0.9072 - val_loss: 11294.9287 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 10842.46094\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11067.0449 - accuracy: 0.9059 - val_loss: 11542.3203 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 10842.46094\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10747.4160 - accuracy: 0.9078 - val_loss: 11687.1279 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 10842.46094\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10916.4033 - accuracy: 0.9047 - val_loss: 11442.3320 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 10842.46094\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 10572.3066 - accuracy: 0.9114 - val_loss: 11066.3398 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 10842.46094\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 10784.6523 - accuracy: 0.9086 - val_loss: 12218.0410 - val_accuracy: 0.8985\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 10842.46094\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11159.7383 - accuracy: 0.9100 - val_loss: 11998.3447 - val_accuracy: 0.8985\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 10842.46094\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11328.6855 - accuracy: 0.9097 - val_loss: 11548.9072 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 10842.46094\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10770.2285 - accuracy: 0.9078 - val_loss: 10990.9043 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 10842.46094\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10613.4922 - accuracy: 0.9092 - val_loss: 11251.8203 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 10842.46094\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10616.7373 - accuracy: 0.9072 - val_loss: 11798.9473 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 10842.46094\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 11255.8193 - accuracy: 0.9075 - val_loss: 12266.1797 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 10842.46094\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 10573.1494 - accuracy: 0.9097 - val_loss: 11504.9775 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 10842.46094\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 10682.3135 - accuracy: 0.9092 - val_loss: 11052.3301 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 10842.46094\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10486.1387 - accuracy: 0.9105 - val_loss: 11398.4043 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 10842.46094\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10589.5664 - accuracy: 0.9114 - val_loss: 11053.8789 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 10842.46094\n",
      "Epoch 256/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 10622.8223 - accuracy: 0.9089 - val_loss: 12019.7812 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 10842.46094\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10384.4336 - accuracy: 0.9097 - val_loss: 11333.1621 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 10842.46094\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10798.2363 - accuracy: 0.9103 - val_loss: 11914.1523 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 10842.46094\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10473.0967 - accuracy: 0.9097 - val_loss: 11930.3662 - val_accuracy: 0.9338\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 10842.46094\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10681.2490 - accuracy: 0.9097 - val_loss: 10450.1426 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00260: val_loss improved from 10842.46094 to 10450.14258, saving model to Weights-260--10450.14258.hdf5\n",
      "Epoch 261/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10328.0400 - accuracy: 0.9114 - val_loss: 10761.6016 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 10450.14258\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10455.6973 - accuracy: 0.9105 - val_loss: 11178.7637 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 10450.14258\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10721.4395 - accuracy: 0.9083 - val_loss: 10609.0850 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 10450.14258\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10519.9746 - accuracy: 0.9136 - val_loss: 11128.6895 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 10450.14258\n",
      "Epoch 265/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10282.4951 - accuracy: 0.9114 - val_loss: 10903.1807 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 10450.14258\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10444.9941 - accuracy: 0.9103 - val_loss: 10797.8623 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 10450.14258\n",
      "Epoch 267/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10567.2988 - accuracy: 0.9136 - val_loss: 10855.5605 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 10450.14258\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10973.6201 - accuracy: 0.9141 - val_loss: 10712.0752 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 10450.14258\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10871.1133 - accuracy: 0.9117 - val_loss: 11749.5146 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 10450.14258\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10527.8730 - accuracy: 0.9105 - val_loss: 11213.2969 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 10450.14258\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 10445.5205 - accuracy: 0.9122 - val_loss: 12030.2832 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 10450.14258\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10730.9883 - accuracy: 0.9089 - val_loss: 10955.7744 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 10450.14258\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10223.1826 - accuracy: 0.9105 - val_loss: 11010.8711 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 10450.14258\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10311.3223 - accuracy: 0.9128 - val_loss: 11221.4814 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 10450.14258\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10736.7861 - accuracy: 0.9114 - val_loss: 10790.3369 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 10450.14258\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 10257.7822 - accuracy: 0.9150 - val_loss: 10556.0703 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 10450.14258\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10427.3828 - accuracy: 0.9111 - val_loss: 10570.4902 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 10450.14258\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10073.0625 - accuracy: 0.9100 - val_loss: 11185.2734 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 10450.14258\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10218.9990 - accuracy: 0.9094 - val_loss: 10537.7773 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 10450.14258\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10057.9717 - accuracy: 0.9105 - val_loss: 10564.2471 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 10450.14258\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10145.7012 - accuracy: 0.9125 - val_loss: 10673.9434 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 10450.14258\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10288.4629 - accuracy: 0.9133 - val_loss: 10132.3535 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00282: val_loss improved from 10450.14258 to 10132.35352, saving model to Weights-282--10132.35352.hdf5\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10274.5391 - accuracy: 0.9147 - val_loss: 10953.3438 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 10132.35352\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10908.5127 - accuracy: 0.9119 - val_loss: 10144.2549 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 10132.35352\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10201.8838 - accuracy: 0.9122 - val_loss: 11123.1357 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 10132.35352\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 10077.2412 - accuracy: 0.9136 - val_loss: 10869.7217 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 10132.35352\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10482.7539 - accuracy: 0.9147 - val_loss: 11042.1758 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 10132.35352\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10200.7783 - accuracy: 0.9139 - val_loss: 10587.7061 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 10132.35352\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10277.1055 - accuracy: 0.9139 - val_loss: 10376.2207 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 10132.35352\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10157.1807 - accuracy: 0.9108 - val_loss: 10532.5674 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 10132.35352\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10169.9180 - accuracy: 0.9119 - val_loss: 11086.4912 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 10132.35352\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10380.3643 - accuracy: 0.9183 - val_loss: 10804.3555 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 10132.35352\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10716.2666 - accuracy: 0.9194 - val_loss: 10705.1240 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 10132.35352\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10387.6846 - accuracy: 0.9111 - val_loss: 12150.0361 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 10132.35352\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 10350.9727 - accuracy: 0.9172 - val_loss: 10761.2139 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 10132.35352\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10142.2891 - accuracy: 0.9125 - val_loss: 10445.1689 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 10132.35352\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9911.0400 - accuracy: 0.9139 - val_loss: 10202.8369 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 10132.35352\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 9953.1299 - accuracy: 0.9152 - val_loss: 10365.7393 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 10132.35352\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9838.5098 - accuracy: 0.9163 - val_loss: 10492.7637 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 10132.35352\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10033.5635 - accuracy: 0.9141 - val_loss: 10533.3320 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 10132.35352\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10174.3896 - accuracy: 0.9130 - val_loss: 10493.1787 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 10132.35352\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10043.6436 - accuracy: 0.9152 - val_loss: 10491.1104 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 10132.35352\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10020.6572 - accuracy: 0.9119 - val_loss: 10117.7188 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00303: val_loss improved from 10132.35352 to 10117.71875, saving model to Weights-303--10117.71875.hdf5\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9950.5742 - accuracy: 0.9152 - val_loss: 10929.8828 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 10117.71875\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9793.4238 - accuracy: 0.9130 - val_loss: 11630.2422 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 10117.71875\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9910.8496 - accuracy: 0.9117 - val_loss: 10505.8721 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 10117.71875\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10113.7480 - accuracy: 0.9141 - val_loss: 10717.9238 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 10117.71875\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10278.4072 - accuracy: 0.9117 - val_loss: 11682.5762 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 10117.71875\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10034.4385 - accuracy: 0.9094 - val_loss: 9864.4131 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00309: val_loss improved from 10117.71875 to 9864.41309, saving model to Weights-309--9864.41309.hdf5\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9947.1025 - accuracy: 0.9141 - val_loss: 11493.2930 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 9864.41309\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9778.5703 - accuracy: 0.9158 - val_loss: 11336.5312 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 9864.41309\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9972.2373 - accuracy: 0.9136 - val_loss: 10412.3633 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 9864.41309\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9556.3301 - accuracy: 0.9155 - val_loss: 9801.1719 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00313: val_loss improved from 9864.41309 to 9801.17188, saving model to Weights-313--9801.17188.hdf5\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9649.1807 - accuracy: 0.9130 - val_loss: 9926.7852 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 9801.17188\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9676.9453 - accuracy: 0.9128 - val_loss: 10597.3203 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 9801.17188\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9734.2510 - accuracy: 0.9158 - val_loss: 10216.6377 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 9801.17188\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10128.3301 - accuracy: 0.9174 - val_loss: 10499.1768 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 9801.17188\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 9927.1660 - accuracy: 0.9163 - val_loss: 9644.4932 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00318: val_loss improved from 9801.17188 to 9644.49316, saving model to Weights-318--9644.49316.hdf5\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9488.6055 - accuracy: 0.9180 - val_loss: 10787.8662 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 9644.49316\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9861.0264 - accuracy: 0.9114 - val_loss: 10317.2783 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 9644.49316\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9569.2461 - accuracy: 0.9166 - val_loss: 10061.7383 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 9644.49316\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9562.2295 - accuracy: 0.9119 - val_loss: 9920.0137 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 9644.49316\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9691.0459 - accuracy: 0.9163 - val_loss: 10383.7861 - val_accuracy: 0.9040\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 9644.49316\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9833.8828 - accuracy: 0.9144 - val_loss: 9456.5732 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00324: val_loss improved from 9644.49316 to 9456.57324, saving model to Weights-324--9456.57324.hdf5\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9604.6973 - accuracy: 0.9183 - val_loss: 11307.7793 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 9456.57324\n",
      "Epoch 326/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9931.9697 - accuracy: 0.9166 - val_loss: 9782.3701 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 9456.57324\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9383.9678 - accuracy: 0.9155 - val_loss: 11263.3809 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 9456.57324\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9568.9502 - accuracy: 0.9152 - val_loss: 10448.0400 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 9456.57324\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9531.3516 - accuracy: 0.9125 - val_loss: 9920.9395 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 9456.57324\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9743.8418 - accuracy: 0.9177 - val_loss: 10285.6865 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 9456.57324\n",
      "Epoch 331/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 10103.8096 - accuracy: 0.9133 - val_loss: 9985.3418 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 9456.57324\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9426.7920 - accuracy: 0.9155 - val_loss: 9702.8535 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 9456.57324\n",
      "Epoch 333/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 9999.2764 - accuracy: 0.9130 - val_loss: 9990.7627 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 9456.57324\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9564.4297 - accuracy: 0.9152 - val_loss: 10452.1592 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 9456.57324\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9462.4404 - accuracy: 0.9172 - val_loss: 10462.2812 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 9456.57324\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9542.8633 - accuracy: 0.9125 - val_loss: 10598.1367 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 9456.57324\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9322.7598 - accuracy: 0.9169 - val_loss: 9938.0156 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 9456.57324\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9967.9561 - accuracy: 0.9197 - val_loss: 9775.7793 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 9456.57324\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9664.7334 - accuracy: 0.9103 - val_loss: 10508.1416 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 9456.57324\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9560.6992 - accuracy: 0.9174 - val_loss: 11635.7100 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 9456.57324\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9388.6514 - accuracy: 0.9197 - val_loss: 9483.9160 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 9456.57324\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9486.0938 - accuracy: 0.9177 - val_loss: 9498.2451 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 9456.57324\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9306.0850 - accuracy: 0.9158 - val_loss: 10472.8906 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 9456.57324\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9335.0479 - accuracy: 0.9130 - val_loss: 9884.5645 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 9456.57324\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9574.6670 - accuracy: 0.9147 - val_loss: 10251.6016 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 9456.57324\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9357.0176 - accuracy: 0.9172 - val_loss: 9769.8066 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 9456.57324\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 9628.5986 - accuracy: 0.9150 - val_loss: 10170.3066 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 9456.57324\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 9554.8066 - accuracy: 0.9172 - val_loss: 11502.6348 - val_accuracy: 0.9338\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 9456.57324\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9278.5459 - accuracy: 0.9169 - val_loss: 9818.1953 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 9456.57324\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9558.0098 - accuracy: 0.9210 - val_loss: 9931.0439 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 9456.57324\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9279.8125 - accuracy: 0.9177 - val_loss: 9647.0938 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 9456.57324\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9131.0225 - accuracy: 0.9163 - val_loss: 9800.6797 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 9456.57324\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9309.8984 - accuracy: 0.9172 - val_loss: 10526.5186 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 9456.57324\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9215.7949 - accuracy: 0.9169 - val_loss: 9985.7461 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 9456.57324\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9180.3701 - accuracy: 0.9174 - val_loss: 10262.2178 - val_accuracy: 0.9426\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 9456.57324\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9337.0732 - accuracy: 0.9244 - val_loss: 9800.8867 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 9456.57324\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9182.5420 - accuracy: 0.9183 - val_loss: 10039.3750 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 9456.57324\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9132.5771 - accuracy: 0.9183 - val_loss: 11260.7480 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 9456.57324\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9300.0830 - accuracy: 0.9194 - val_loss: 11144.8574 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 9456.57324\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9343.3838 - accuracy: 0.9205 - val_loss: 10193.7607 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 9456.57324\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9197.7832 - accuracy: 0.9183 - val_loss: 10492.0703 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 9456.57324\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9593.1064 - accuracy: 0.9174 - val_loss: 9165.5752 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00362: val_loss improved from 9456.57324 to 9165.57520, saving model to Weights-362--9165.57520.hdf5\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9316.7451 - accuracy: 0.9210 - val_loss: 9144.2959 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00363: val_loss improved from 9165.57520 to 9144.29590, saving model to Weights-363--9144.29590.hdf5\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8811.1914 - accuracy: 0.9241 - val_loss: 10377.2988 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 9144.29590\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9525.7314 - accuracy: 0.9235 - val_loss: 9693.2266 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 9144.29590\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8804.7969 - accuracy: 0.9252 - val_loss: 9144.7109 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 9144.29590\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9197.9482 - accuracy: 0.9202 - val_loss: 11291.3252 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 9144.29590\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9141.8193 - accuracy: 0.9208 - val_loss: 9304.8184 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 9144.29590\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9414.2510 - accuracy: 0.9163 - val_loss: 9459.9346 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 9144.29590\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8808.6973 - accuracy: 0.9197 - val_loss: 9583.7695 - val_accuracy: 0.9448\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 9144.29590\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9131.6201 - accuracy: 0.9210 - val_loss: 9634.0059 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 9144.29590\n",
      "Epoch 372/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 8933.9102 - accuracy: 0.9221 - val_loss: 9669.7100 - val_accuracy: 0.9448\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 9144.29590\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8943.7959 - accuracy: 0.9191 - val_loss: 10173.1631 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 9144.29590\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9109.8252 - accuracy: 0.9163 - val_loss: 10782.7793 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 9144.29590\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9103.0518 - accuracy: 0.9194 - val_loss: 9248.9648 - val_accuracy: 0.9338\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 9144.29590\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8955.8242 - accuracy: 0.9224 - val_loss: 9389.7305 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 9144.29590\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8797.7617 - accuracy: 0.9158 - val_loss: 9650.2324 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 9144.29590\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8880.8506 - accuracy: 0.9205 - val_loss: 9519.6182 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 9144.29590\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8645.7559 - accuracy: 0.9216 - val_loss: 8991.8994 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00379: val_loss improved from 9144.29590 to 8991.89941, saving model to Weights-379--8991.89941.hdf5\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9047.1416 - accuracy: 0.9191 - val_loss: 9140.0117 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 8991.89941\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8935.7480 - accuracy: 0.9244 - val_loss: 9575.9336 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 8991.89941\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 9207.7148 - accuracy: 0.9183 - val_loss: 10448.3779 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 8991.89941\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9249.5635 - accuracy: 0.9244 - val_loss: 9095.6973 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 8991.89941\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8989.4551 - accuracy: 0.9205 - val_loss: 10474.5742 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 8991.89941\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8827.0342 - accuracy: 0.9210 - val_loss: 8904.8232 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 00385: val_loss improved from 8991.89941 to 8904.82324, saving model to Weights-385--8904.82324.hdf5\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8666.1172 - accuracy: 0.9230 - val_loss: 8799.2295 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00386: val_loss improved from 8904.82324 to 8799.22949, saving model to Weights-386--8799.22949.hdf5\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8854.4707 - accuracy: 0.9241 - val_loss: 9710.3564 - val_accuracy: 0.9581\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 8799.22949\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9047.8291 - accuracy: 0.9230 - val_loss: 9734.4951 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 8799.22949\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8738.4033 - accuracy: 0.9183 - val_loss: 9425.5449 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 8799.22949\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8959.2236 - accuracy: 0.9230 - val_loss: 8754.4893 - val_accuracy: 0.9393\n",
      "\n",
      "Epoch 00390: val_loss improved from 8799.22949 to 8754.48926, saving model to Weights-390--8754.48926.hdf5\n",
      "Epoch 391/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8870.2598 - accuracy: 0.9230 - val_loss: 9750.5938 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 8754.48926\n",
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8609.1201 - accuracy: 0.9249 - val_loss: 9354.1152 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 8754.48926\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8700.5869 - accuracy: 0.9172 - val_loss: 9269.6426 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 8754.48926\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8796.2490 - accuracy: 0.9202 - val_loss: 9102.4062 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 8754.48926\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8617.5264 - accuracy: 0.9227 - val_loss: 9995.4170 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 8754.48926\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8905.1230 - accuracy: 0.9199 - val_loss: 9049.8496 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 8754.48926\n",
      "Epoch 397/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8408.2930 - accuracy: 0.9232 - val_loss: 9560.8398 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 8754.48926\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8950.9229 - accuracy: 0.9227 - val_loss: 10295.4521 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 8754.48926\n",
      "Epoch 399/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9185.0977 - accuracy: 0.9205 - val_loss: 10286.9014 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 8754.48926\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8945.0586 - accuracy: 0.9221 - val_loss: 8978.0596 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 8754.48926\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8575.8740 - accuracy: 0.9199 - val_loss: 8748.9111 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00401: val_loss improved from 8754.48926 to 8748.91113, saving model to Weights-401--8748.91113.hdf5\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8672.2314 - accuracy: 0.9288 - val_loss: 8883.2930 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 8748.91113\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8714.2861 - accuracy: 0.9246 - val_loss: 9035.3262 - val_accuracy: 0.9338\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 8748.91113\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8521.5928 - accuracy: 0.9296 - val_loss: 9952.2852 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 8748.91113\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8766.2070 - accuracy: 0.9227 - val_loss: 9352.7305 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 8748.91113\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8630.0107 - accuracy: 0.9244 - val_loss: 8850.8076 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 8748.91113\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8552.6641 - accuracy: 0.9274 - val_loss: 9717.3594 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 8748.91113\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8949.5322 - accuracy: 0.9213 - val_loss: 8478.6582 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00408: val_loss improved from 8748.91113 to 8478.65820, saving model to Weights-408--8478.65820.hdf5\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8487.5967 - accuracy: 0.9285 - val_loss: 9699.7979 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 8478.65820\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 8696.5459 - accuracy: 0.9230 - val_loss: 9577.1982 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 8478.65820\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8625.1113 - accuracy: 0.9299 - val_loss: 9229.6660 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 8478.65820\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8492.5225 - accuracy: 0.9288 - val_loss: 10388.9717 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 8478.65820\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8618.4092 - accuracy: 0.9183 - val_loss: 8655.4082 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 8478.65820\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8677.2441 - accuracy: 0.9263 - val_loss: 9094.0156 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 8478.65820\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9154.3887 - accuracy: 0.9255 - val_loss: 9535.9229 - val_accuracy: 0.9040\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 8478.65820\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8546.5527 - accuracy: 0.9235 - val_loss: 9408.7207 - val_accuracy: 0.9393\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 8478.65820\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8933.1172 - accuracy: 0.9221 - val_loss: 9353.9629 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 8478.65820\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8558.8828 - accuracy: 0.9210 - val_loss: 8862.1514 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 8478.65820\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8909.6348 - accuracy: 0.9230 - val_loss: 11775.4385 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 8478.65820\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9028.2168 - accuracy: 0.9335 - val_loss: 9151.6387 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 8478.65820\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8490.6660 - accuracy: 0.9307 - val_loss: 8722.0283 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 8478.65820\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8505.9688 - accuracy: 0.9241 - val_loss: 9222.3418 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 8478.65820\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8360.6221 - accuracy: 0.9249 - val_loss: 9293.8652 - val_accuracy: 0.9592\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 8478.65820\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8508.6455 - accuracy: 0.9313 - val_loss: 9045.1221 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 8478.65820\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8220.8018 - accuracy: 0.9260 - val_loss: 9058.2656 - val_accuracy: 0.9603\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 8478.65820\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8663.5791 - accuracy: 0.9288 - val_loss: 8760.0225 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 8478.65820\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8595.5088 - accuracy: 0.9219 - val_loss: 8859.3223 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 8478.65820\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8292.6826 - accuracy: 0.9219 - val_loss: 9502.1279 - val_accuracy: 0.9603\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 8478.65820\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8994.5000 - accuracy: 0.9299 - val_loss: 8999.4199 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 8478.65820\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8280.1650 - accuracy: 0.9235 - val_loss: 8787.6592 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 8478.65820\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8582.0840 - accuracy: 0.9271 - val_loss: 9271.2324 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 8478.65820\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8416.2539 - accuracy: 0.9282 - val_loss: 9033.0156 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 8478.65820\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8741.4912 - accuracy: 0.9257 - val_loss: 9078.2090 - val_accuracy: 0.9636\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 8478.65820\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8342.3623 - accuracy: 0.9268 - val_loss: 9673.8721 - val_accuracy: 0.9470\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 8478.65820\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8528.3389 - accuracy: 0.9255 - val_loss: 8570.3164 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 8478.65820\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8201.2236 - accuracy: 0.9235 - val_loss: 8649.3242 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 8478.65820\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8320.0879 - accuracy: 0.9279 - val_loss: 8433.4150 - val_accuracy: 0.9603\n",
      "\n",
      "Epoch 00437: val_loss improved from 8478.65820 to 8433.41504, saving model to Weights-437--8433.41504.hdf5\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8108.9834 - accuracy: 0.9241 - val_loss: 8242.6758 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00438: val_loss improved from 8433.41504 to 8242.67578, saving model to Weights-438--8242.67578.hdf5\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8527.8809 - accuracy: 0.9274 - val_loss: 9596.9150 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 8242.67578\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8375.0820 - accuracy: 0.9296 - val_loss: 9234.8242 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 8242.67578\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8462.3135 - accuracy: 0.9238 - val_loss: 8949.2314 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 8242.67578\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8628.4736 - accuracy: 0.9304 - val_loss: 9481.7021 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 8242.67578\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 9025.8018 - accuracy: 0.9235 - val_loss: 8751.3799 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 8242.67578\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8866.0430 - accuracy: 0.9274 - val_loss: 10398.6846 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 8242.67578\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8889.1377 - accuracy: 0.9219 - val_loss: 8911.2021 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 8242.67578\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8226.2119 - accuracy: 0.9199 - val_loss: 8837.3789 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 8242.67578\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8036.6719 - accuracy: 0.9257 - val_loss: 8981.2656 - val_accuracy: 0.9592\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 8242.67578\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8246.2158 - accuracy: 0.9230 - val_loss: 9163.3320 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 8242.67578\n",
      "Epoch 449/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 8043.2207 - accuracy: 0.9277 - val_loss: 8734.8330 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 8242.67578\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8536.0332 - accuracy: 0.9268 - val_loss: 8467.3564 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 8242.67578\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8026.2080 - accuracy: 0.9290 - val_loss: 8970.0635 - val_accuracy: 0.9503\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 8242.67578\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8352.0244 - accuracy: 0.9274 - val_loss: 9253.8740 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 8242.67578\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8345.3408 - accuracy: 0.9329 - val_loss: 9038.2324 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 8242.67578\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8186.7886 - accuracy: 0.9277 - val_loss: 8590.4268 - val_accuracy: 0.9625\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 8242.67578\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8280.0010 - accuracy: 0.9288 - val_loss: 9676.4395 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 8242.67578\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 7939.1460 - accuracy: 0.9268 - val_loss: 8466.9355 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 8242.67578\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8042.2432 - accuracy: 0.9288 - val_loss: 8912.1660 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 8242.67578\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8103.3320 - accuracy: 0.9246 - val_loss: 9505.8311 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 8242.67578\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8155.6865 - accuracy: 0.9238 - val_loss: 9489.6553 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 8242.67578\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8553.9639 - accuracy: 0.9282 - val_loss: 8926.5703 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 8242.67578\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8069.9917 - accuracy: 0.9213 - val_loss: 8266.9277 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 8242.67578\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8167.8198 - accuracy: 0.9268 - val_loss: 9124.1523 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 8242.67578\n",
      "Epoch 463/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 7900.3921 - accuracy: 0.9313 - val_loss: 9450.7217 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 8242.67578\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8576.5156 - accuracy: 0.9271 - val_loss: 8193.1318 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00464: val_loss improved from 8242.67578 to 8193.13184, saving model to Weights-464--8193.13184.hdf5\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8402.3301 - accuracy: 0.9329 - val_loss: 9080.5137 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 8193.13184\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8212.6934 - accuracy: 0.9227 - val_loss: 8745.0195 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 8193.13184\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 7928.2500 - accuracy: 0.9296 - val_loss: 8303.2881 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 8193.13184\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7991.2534 - accuracy: 0.9257 - val_loss: 9398.1406 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 8193.13184\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8141.6157 - accuracy: 0.9260 - val_loss: 9065.6885 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 8193.13184\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8135.2676 - accuracy: 0.9282 - val_loss: 8407.2217 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 8193.13184\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8353.9932 - accuracy: 0.9271 - val_loss: 10138.8633 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 8193.13184\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8269.9326 - accuracy: 0.9359 - val_loss: 9123.6631 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 8193.13184\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7813.1294 - accuracy: 0.9310 - val_loss: 8714.1992 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 8193.13184\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7855.2715 - accuracy: 0.9266 - val_loss: 8965.3584 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 8193.13184\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7791.0215 - accuracy: 0.9288 - val_loss: 9496.2812 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 8193.13184\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8243.8486 - accuracy: 0.9290 - val_loss: 8126.3501 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00476: val_loss improved from 8193.13184 to 8126.35010, saving model to Weights-476--8126.35010.hdf5\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8191.5918 - accuracy: 0.9324 - val_loss: 9139.9893 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 8126.35010\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8105.4849 - accuracy: 0.9274 - val_loss: 8454.8408 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 8126.35010\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8360.4209 - accuracy: 0.9271 - val_loss: 8455.8877 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 8126.35010\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8059.0762 - accuracy: 0.9255 - val_loss: 8484.2383 - val_accuracy: 0.9558\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 8126.35010\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7868.5840 - accuracy: 0.9337 - val_loss: 9763.2637 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 8126.35010\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8141.4370 - accuracy: 0.9296 - val_loss: 9549.6553 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 8126.35010\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8051.3413 - accuracy: 0.9293 - val_loss: 8688.7432 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 8126.35010\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7926.1177 - accuracy: 0.9252 - val_loss: 8288.7871 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 8126.35010\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7880.5566 - accuracy: 0.9296 - val_loss: 8698.2354 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 8126.35010\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8192.0312 - accuracy: 0.9296 - val_loss: 8739.8115 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 8126.35010\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8348.2861 - accuracy: 0.9335 - val_loss: 10756.8389 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 8126.35010\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 8107.1636 - accuracy: 0.9271 - val_loss: 8650.6797 - val_accuracy: 0.9470\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 8126.35010\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8099.1938 - accuracy: 0.9315 - val_loss: 10157.8662 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 8126.35010\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7762.0815 - accuracy: 0.9293 - val_loss: 7929.2134 - val_accuracy: 0.9470\n",
      "\n",
      "Epoch 00490: val_loss improved from 8126.35010 to 7929.21338, saving model to Weights-490--7929.21338.hdf5\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8189.6118 - accuracy: 0.9299 - val_loss: 8870.5059 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 7929.21338\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7638.7466 - accuracy: 0.9277 - val_loss: 9102.2764 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 7929.21338\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7884.6069 - accuracy: 0.9277 - val_loss: 8327.6768 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 7929.21338\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7492.9224 - accuracy: 0.9282 - val_loss: 8069.8521 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 7929.21338\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7620.1313 - accuracy: 0.9332 - val_loss: 8335.9297 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 7929.21338\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7735.0913 - accuracy: 0.9255 - val_loss: 8476.1025 - val_accuracy: 0.9547\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 7929.21338\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8018.8784 - accuracy: 0.9329 - val_loss: 8928.7148 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 7929.21338\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8117.7246 - accuracy: 0.9304 - val_loss: 9549.9170 - val_accuracy: 0.9581\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 7929.21338\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 7778.3301 - accuracy: 0.9246 - val_loss: 9245.3379 - val_accuracy: 0.9503\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 7929.21338\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 8179.9888 - accuracy: 0.9321 - val_loss: 9310.6875 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 7929.21338\n"
     ]
    }
   ],
   "source": [
    "# define checkpoint callback\n",
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "history = dl_model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ccc0961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(0,500)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c7f23e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 597us/step - loss: 10467.2842 - mean_absolute_error: 10467.2842\n",
      "mean_absolute_error: 1046728.42%\n"
     ]
    }
   ],
   "source": [
    "# Load wights file of the best model :\n",
    "wights_file = 'Weights-495--11249.85938.hdf5' # choose the best checkpoint \n",
    "dl_model.load_weights(wights_file) # load it\n",
    "dl_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "result = dl_model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (dl_model.metrics_names[1], result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4ebb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
